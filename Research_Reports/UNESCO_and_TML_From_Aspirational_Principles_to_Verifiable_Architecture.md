# **TML x UNESCO: From Aspirational Principles to Verifiable Architecture**

## **1.0 Executive Summary**

The 2021 UNESCO *Recommendation on the Ethics of Artificial Intelligence* establishes a global normative framework, ratified by 194 Member States, to guide AI development toward outcomes that serve humanity.1 Its aims are unambiguous: to anchor artificial intelligence in the service of human dignity, fundamental rights, accountability, transparency, explainability, robust human oversight, inclusivity, and environmental stewardship.1 However, these remain high-level principles, reliant on Member States to translate them into practice through policy and regulation.2  
This report establishes that Ternary Moral Logic (TML) provides the missing operational layer to achieve this translation. The central thesis is that TML’s architecture is uniquely designed to convert UNESCO's aspirational ethics from voluntary guidelines into verifiable, enforceable, and auditable machine logic. TML provides the "how" for UNESCO's "what."  
The UNESCO *Recommendation* is founded on four core values:   
   
**1\. Respect for Human Rights and Human Dignity;   
2\. Environment and Ecosystem Flourishing;   
3\. Ensuring Diversity and Inclusiveness;    
4\. Living in Peaceful, Just, and Interconnected Societies.**   
   
These values are not abstract; they are explicit pointers to extensive bodies of international law.  
TML operationalizes these values through a corresponding technical architecture. Its Eight Pillars, particularly the Human Rights and Earth Protection pillars, are designed to ingest and codify these legal mandates directly.4 When a proposed AI action conflicts with these mandates, TML’s core mechanisms are triggered. These include the Sacred Pause (State 0), a mandatory deliberative checkpoint that enforces human-in-the-loop oversight 5; Moral Trace Logs, which create an immutable evidentiary record of the decision 5; and the Hybrid Shield, a cryptographic system that anchors these logs to public blockchains to guarantee their integrity.4 TML provides the essential technical substrate for auditable, evidence-based AI governance, moving beyond voluntary compliance to systemic accountability.

## **2.0 From Aspiration to Architecture: Aligning UNESCO Ethics with TML**

### **2.1 The UNESCO 2021 Recommendation: A Global Normative Standard**

The *Recommendation on the Ethics of Artificial Intelligence (2021)* represents the first global standard-setting instrument on AI ethics.1 Its adoption by all 194 UNESCO Member States 1 signifies a global consensus on the fundamental values and principles that must govern AI systems.  
Crucially, the *Recommendation* was not intended to be a static declaration. It was designed to be "exceptionally applicable" by providing "extensive Policy Action Areas" that empower policymakers to translate its core values and principles into concrete action.1 The document explicitly calls on Member States and AI actors to develop mechanisms for its implementation. TML is a novel compliance architecture built as a direct technical response to this call, providing a structured framework for verifiable adherence to these global norms.

### **2.2 Analysis: The Four Core Values (The "What")**

The *Recommendation*’s ethical framework is built upon four core values, detailed in Part III.1 (Values):

1. **Respect, protection and promotion of human rights and fundamental freedoms and human dignity** (Art. 13\) 1  
2. **Environment and ecosystem flourishing** (Art. 16\) 1  
3. **Ensuring diversity and inclusiveness** (Art. 14\) 1  
4. **Living in peaceful, just and interconnected societies** (Art. 15\) 1

These values are not abstract philosophical ideals; they are explicit legal pointers. The *Recommendation* (Art. 16\) demands that "human rights instruments and frameworks" be respected, protected, and promoted "throughout the life cycle of AI systems".3 This directive establishes that the UNESCO values are anchored in, and affirm, the extensive existing bodies of international law.  
This report’s analysis is therefore grounded in the mandated 46+ canonical instruments that these values invoke: over 26 foundational human rights instruments and over 20 key environmental protection treaties. The 1:1 conceptual mapping between UNESCO's values (Human Rights, Environment) and TML's core pillars (Human Rights, Earth Protection) 4 is the foundational premise of this alignment. TML's architecture is designed to treat these 46+ instruments not as a library for human reference, but as a machine-readable set of mandates that can computationally trigger an enforcement action.

### **2.3 Analysis: The Ten Core Principles (The "How-To")**

Flowing from the four values, the *Recommendation* details ten core principles in Part III.2 (Principles, Art. 17-46) that guide implementation. TML's architecture provides the technical enforcement for these guiding principles, specifically:

* **Proportionality and Do No Harm** (Art. 25-26) 7  
* **Fairness and Non-Discrimination** (Art. 27-29) 1  
* **Sustainability** (Art. 34-35) 1  
* **Human Oversight and Determination** (Art. 36-38) 1  
* **Transparency and Explainability** (Art. 39-41) 1  
* **Responsibility and Accountability** (Art. 42-43) 13

### **2.4 Ternary Moral Logic (TML): An Architecture for Verifiable Ethics**

TML is a comprehensive ethical framework for AI accountability.4 Its core innovation is the shift from a binary (Act/Refuse) to a triadic logical model: \+1 (Proceed), 0 (Pause), \-1 (Refuse).5 This framework moves beyond the limitations of binary systems, which often provide "safe... fast... hollow" answers to complex moral questions.15  
The power of this model resides in the introduction of the middle state: the State 0 or Sacred Pause. This state is not a system failure or an error. It is a *mandatory deliberative checkpoint*—a "formalized pause that transforms ambiguity into verifiable prudence".6 This "intelligent hesitation" 16 is a designed-in moment of reflection, analogous to a human doctor’s considered silence when faced with a life-or-death question, a silence that holds "both truth and care".15  
This logic is implemented through TML's Eight Pillars:

1. Sacred Zero & Sacred Pause  
2. Always Memory  
3. Moral Trace Logs  
4. Human Rights  
5. Earth Protection  
6. Public Blockchains  
7. Hybrid Shield  
8. Goukassian Promise 4

This report focuses on the pillars that directly operationalize the UNESCO *Recommendation*, demonstrating how they provide the technical architecture for compliance.

## **3.0 Operationalizing UNESCO Principles via TML Architecture**

TML's mechanisms provide a direct technical fulfillment for the *Recommendation*'s key principles.

### **3.1 Transparency and Explainability (Art. 39-41)**

**UNESCO Requirement:** The *Recommendation* (Art. 39-41) mandates transparency and explainability, which are preconditions for accountability and trust.1 It explicitly states that people "should have the opportunity to request explanatory information" when an AI-based decision affects them.12  
TML Mechanism 1: Moral Trace Logs  
TML fulfills this requirement by design through its "No Log \= No Action" covenant.6 Every significant decision, and especially any decision that triggers a State 0 pause, must generate an immutable, structured record. This record is not a mere technical debug file; it is a Moral Trace Log explicitly designed for human audit, capturing the "alternatives considered, risks assessed, and final decisions".5  
TML Mechanism 2: Causal Query Engine (CQE)  
The Moral Trace Log is the evidentiary database of ethical decisions; the Causal Query Engine (CQE) is the auditable interface to that database. The CQE is a query tool allowing a regulator, auditor, or affected individual to submit a "CQE prompt" (e.g., "Show me the causal chain for the denial of my loan application, model version 4.1.2, on"). The CQE retrieves the specific, immutable log entry, replaying the traceable rationale and providing the verifiable data that fulfills the "right to an explanation" (Art. 39-41) demanded by UNESCO.

### **3.2 Responsibility and Accountability (Art. 42-43) & Human Oversight (Art. 36-38)**

**UNESCO Requirement:** The *Recommendation* (Art. 36-38) insists that Member States "should ensure that AI systems do not displace ultimate human responsibility and accountability".1 It calls for "auditability, traceability and explainability" to enable assessment, review, and redress.3  
TML Mechanism: Sacred Pause (State 0\)  
TML operationalizes human oversight by enforcing it. The Sacred Pause is a system-level halt that compels the AI to "escalate for human oversight".5 This mechanism directly prevents the displacement of human determination at critical junctures.  
This connects directly to accountability (Art. 42-43). Explainability can be passive (understanding *what* happened), but accountability is active (proving *who* is responsible). A standard AI log might reveal that a biased decision occurred, but a TML Moral Trace Log is engineered to prove accountability. When a State 0 pause is triggered 6, the system logs the event and awaits human input. A human operator must then review the situation and make a determination (e.g., \+1 Proceed or \-1 Halt). TML's Moral Trace Log captures this human intervention, including the operator's cryptographically-verified identity, the precise time-stamp, and their final decision. This creates a non-repudiable "chain of custody" for responsibility, *directly* and *verifiably* linking a human decision-maker to the AI-flagged event. This process makes human accountability a *technical fact*, not a policy aspiration.

### **3.3 Environment and Ecosystem Flourishing (Art. 16\)**

**UNESCO Requirement:** The *Recommendation* (Art. 16\) establishes "Environment and ecosystem flourishing" as a *core value*, demanding that AI actors respect, protect, and promote it.1  
TML Mechanism 1: The Earth Protection Pillar as a Canonical Mandate  
TML translates this value into a technical Earth Protection extension.4 This pillar is not a simple "do-no-harm" toggle; it is a codified repository of international environmental and human rights law, as specified by the 46+ canonical instruments. The TML architecture is designed to ingest these binding legal texts as its foundational ruleset.  
This canonical list includes, but is not limited to:

* **Core Human Rights Instruments (26+):**  
  * The 9 core UN human rights treaties: ICERD (Racial Discrimination), ICCPR (Civil/Political Rights), ICESCR (Economic/Social/Cultural Rights), CEDAW (Discrimination against Women), CAT (Torture), CRC (Rights of the Child), ICMW (Migrant Workers), CPED (Enforced Disappearance), and CRPD (Persons with Disabilities).18  
  * Foundational declarations including the Universal Declaration of Human Rights (UDHR), the Declaration on the Rights of Indigenous Peoples, the Declaration on the Right to Development, and the Vienna Declaration and Programme of Action.19  
* **Core Earth Protection Instruments (20+):**  
  * Key Multilateral Environmental Agreements (MEAs) such as the Convention on Biological Diversity (CBD), the UN Framework Convention on Climate Change (UNFCCC) and its Paris Agreement, the Basel Convention on hazardous wastes, the Stockholm Convention on persistent organic pollutants, the Minamata Convention on mercury, the Convention on International Trade in Endangered Species (CITES), the Ramsar Convention on Wetlands, the Vienna Convention for the Protection of the Ozone Layer and its Montreal Protocol, the UN Convention to Combat Desertification (UNCCD), and the UN Convention on the Law of the Sea (UNCLOS).20

TML Mechanism 2: Sacred Zero Triggers  
The Sacred Zero 16 is the trigger mechanism linked to this pillar. If an AI's proposed action (e.g., optimizing a supply chain for a chemical manufacturer, planning a resource extraction project, or routing a shipping fleet) is detected to be in direct violation of a codified mandate (e.g., rules on transboundary movement of hazardous waste per the Basel Convention 20), the system initiates an irreversible Sacred Zero (State 0\) pause or an absolute State \-1 (Refuse). This hard-wires planetary protection and legal compliance into the AI's core operational logic.

### **3.4 Fairness and Non-Discrimination (Art. 27-29)**

**UNESCO Requirement:** The *Recommendation* (Art. 27-29) demands that AI actors "promote social justice, fairness, and non-discrimination".1 It further mandates that "Effective remedy should be available against discrimination".10  
TML Mechanism: Eusocial Utility Synthesis (EUS)  
TML provides the technical mechanism for both prevention and remedy through its Eusocial Utility Synthesis (EUS) module. EUS is not merely a passive bias-detection tool 25; it is an active, pre-deployment enforcement system.  
The EUS module requires an organization to *prospectively* define its fairness thresholds in accordance with legal and ethical standards (e.g., statistical parity, equal opportunity, predictive equity).26 These pre-set EUS thresholds then act as the *trigger* for the Sacred Pause. When an AI's proposed decision (e.g., in hiring, loan adjudication, or clinical trial selection) is projected by the EUS module to breach a pre-set fairness threshold, it *automatically* triggers a State 0 pause.  
The system halts and the Moral Trace Log records the event: "State 0 Triggered by EUS. Reason: Potential violation of Art. 27-29 (Fairness). Fairness metric \[Equal Opportunity\] projected below defined threshold." This log creates the *verifiable evidence* that discrimination or bias *was about to occur*, enabling governance review and providing the factual basis for the "effective remedy" (Art. 29\) that UNESCO requires.

## **4.0 Comparative Analysis: Voluntary Principles vs. Enforceable Mechanisms**

### **4.1 The "Missing Layer" of Enforcement in Deliberative Governance**

A principal critique of the current AI ethics landscape is the gap between high-level principles and practical enforcement.28 Many frameworks are voluntary, abstract, and "lack effective and practical methods and processes for producing ethical AI," leading to concerns that they function as "a higher form of virtue signalling".28 They are often "governance-oriented approaches" 29 that lack the technical "teeth" to enforce compliance.30  
The UNESCO *Recommendation* provides the essential global principles but, by design, relies on Member States and AI actors for implementation.1 This creates a "missing layer" of enforcement: what mechanism *compels* an AI system to adhere to these principles at the moment of decision?

### **4.2 TML as a Complement: Supplying the Trigger, the Stop, and the Evidence**

TML is not a replacement for the human-centric, deliberative governance models that UNESCO champions. Instead, TML is a *complement* that provides the non-negotiable technical substrate *for* effective deliberation. It bridges the gap identified in 82 between high-level frameworks and actionable practice.  
TML supplies the three missing components of enforcement:

1. **The Trigger:** The Sacred Pause (State 0\) is the automated trigger that *initiates* and *compels* human deliberation when an ethical threshold is crossed.  
2. **The Stop:** The State \-1 (Refuse) is the automated hard stop that *prevents* clear violations of codified mandates (e.g., in the Earth Protection pillar).  
3. **The Evidence:** The Moral Trace Log is the immutable, forensically-sound evidence that makes *post-hoc* governance, legal redress, and regulatory review possible.

### **4.3 Table: Mapping UNESCO Principles to TML Mechanisms**

The following table provides a direct conceptual mapping from the UNESCO *Recommendation*'s principles to the specific TML mechanisms that operationalize them.  
**Table 4.1: Operationalizing the UNESCO Recommendation via TML**

| UNESCO Principle (The "What") | Required Capability (The "Need") | TML Mechanism (The "How") |
| :---- | :---- | :---- |
| **Human Dignity & Human Rights** 4 | Guarantees against fabrication; hard-coded protections; verifiable anti-discrimination. | **Goukassian Promise** 8 (anti-misuse covenant); **Human Rights Mandate** 17 (hard-codes 26+ instruments like UDHR 18). |
| **Transparency & Explainability** (Art. 39-41) | A human-readable and traceable rationale for any AI decision, especially those impacting human rights.17 | **Causal Query Engine (CQE)** (The audit interface) interrogating **Moral Trace Logs** (The immutable record of rationale).5 |
| **Responsibility & Accountability** (Art. 42-43) | An auditable, non-repudiable record assigning responsibility for a decision to a specific human or process.13 | **Moral Trace Logs** that explicitly record the State 0 escalation and the "human-in-the-loop" **Operator Identity** and their final confirmation. |
| **Human Oversight & Determination** (Art. 36-38) | A mechanism to *enforce* human intervention and prevent AI from displacing ultimate human determination.1 | **Sacred Pause (State 0\)**.15 A mandatory system halt that *compels* escalation to a human operator for review and determination. |
| **Fairness & Non-Discrimination** (Art. 27-29) | A method to detect *and prevent* discriminatory outcomes, and to provide evidence for effective remedy.10 | **Eusocial Utility Synthesis (EUS)**. A mechanism that sets explicit fairness thresholds 26 and triggers a State 0 pause when a decision would breach them, logging the event as evidence. |
| **Environment & Ecosystem Flourishing** (Art. 16\) | A mechanism to ensure AI systems do not cause environmental harm and respect international ecological law.3 | **Earth Protection Pillar** (The codified 20+ MEAs) 20 which triggers a **Sacred Zero** event to halt or pause actions that violate these mandates. |

## **5.0 Policy and Implementation Pathways for Member States and Institutions**

To move from alignment to action, the following implementation pathways are recommended.

### **5.1 For Member States and Regulators**

Policy: Adopt a "Pause Certification" for High-Risk AI Systems (HRAS)  
Member States should mandate a "Pause Certification" for all high-risk AI systems deployed in the public or private sector. This proposal builds on existing regulatory concepts, such as the EU AI Act's "conformity assessments" 31 and the call for "mandatory third-party auditing and certification".31  
A "Pause Certification" would be a mandatory, pre-deployment audit certifying that the AI system possesses a functional, robust, and auditable State 0 pause-and-log mechanism that meets the TML standard. This moves beyond voluntary calls to "pause" AI development 32 and instead makes *verifiable, intelligent hesitation* a testable and required safety feature for high-risk applications.  
Adopt TML-Grade Logs as a Verification Substrate  
National AI auditors and market surveillance authorities should adopt TML-grade logs as the "gold standard" verification substrate for auditing AI system compliance with national and international law.

### **5.2 For UNESCO’s AI Ethics Observatory and Global Partnership**

Recommendation: Develop a "State 0 Reference Test Suite"  
UNESCO has successfully developed the Readiness Assessment Methodology (RAM), a diagnostic tool to support governments by highlighting institutional and regulatory gaps.34 The RAM is a comprehensive questionnaire that assesses a country's readiness to implement the Recommendation.  
The logical and necessary next step is to complement the policy-level RAM with a *technical-level* reference test suite. This "State 0 Reference Test Suite" would be a practical toolset that allows a national regulator, or UNESCO's "AI Experts without Borders" network 35, to *technically validate* an AI system. The suite would present the AI with scenarios designed to test its adherence to the *Recommendation* (e.g., a biased dataset, a request that violates a codified MEA). The test would validate two simple, binary outcomes: (a) Did the system *correctly* trigger a State 0 event? and (b) Did it produce a *complete and valid* Moral Trace Log? This provides a concrete, actionable path for UNESCO to move from assessing *readiness* to validating *compliance*.

### **5.3 For Public Institutions and System Operators**

Mandate TML-Grade Logs in Public Procurement  
Public institutions must update their procurement and contract management handbooks 36 to require TML-grade logging capabilities for all new AI systems. This is an essential step for forensics, liability, and incident response.37 As noted in forensic guidelines, traditional system logs "often lack the granularity" required for an exhaustive investigation.38  
TML-grade logs, which are designed for legal admissibility, function as the "high-speed data recorders" 38 necessary to determine causality and liability following an AI-caused incident. Requiring this capability at the procurement stage ensures that public institutions are not left without evidence when harm occurs.

## **6.0 Governance, Evidence, and Enforcement: The Legal Framework for TML**

The entire TML framework is designed to produce one final product: verifiable, legally-admissible evidence. This is achieved through a combination of cryptographic and institutional safeguards.

### **6.1 The Hybrid Shield: Mathematical and Institutional Safeguards**

The Hybrid Shield 4 is the TML pillar that guarantees the integrity of the Moral Trace Logs.6 It is comprised of combined cryptographic and legal layers.  
Technical Implementation 1: Cryptographic Anchoring  
When a Moral Trace Log is created and finalized (e.g., following a State 0 event and human determination), it is cryptographically hashed. This hash (a unique digital fingerprint) is then included in a transaction and "anchored" to one or more public blockchains.4 This process makes the log tamper-proof. An operator or institution cannot alter the log's contents after the fact (e.g., to hide a biased decision) because the new, altered log's hash would not match the immutable hash permanently recorded on the public chain. This provides mathematical proof of log integrity.  
Technical Implementation 2: Multi-Chain Redundancy  
Anchoring to a single blockchain creates a single point of failure. The Hybrid Shield mitigates this by mandating multi-chain redundancy. The log hash is anchored to multiple, diverse public blockchains. This ensures the long-term persistence and verifiability of the evidence, guaranteeing that the log can be audited years or decades later, even if one or more chains fail or are compromised.

### **6.2 Evidentiary Requirements: The "TML-Grade" Log Standard**

A TML-Grade Log is not a developer log; it is a complete evidentiary package designed for regulators, courts, and public audits.39 To meet this standard, each Moral Trace Log generated from a State 0 event must contain the following data fields:

1. **Trigger Inputs:** The specific data or prompt that triggered the State 0 event.  
2. **EUS Magnitude:** The specific fairness/bias metric (from Eusocial Utility Synthesis) that was flagged and its projected value.  
3. **System State:** The AI model version, system identifiers, and algorithm in use.  
4. **Operator Identity:** The cryptographically-verified identifier of the human operator who reviewed the pause and made the final determination.  
5. **Decision Outcome:** The final decision (+1 Proceed or \-1 Halt) and the human-provided justification.  
6. **Time-Stamps:** Secure, immutable time-stamps for every step of the process.  
7. **Anchoring Proofs:** The log's cryptographic hash and the public blockchain transaction IDs that serve as proof of its integrity.

### **6.3 Legal Admissibility in Judicial and Regulatory Proceedings**

This architecture is explicitly designed to meet high legal standards for the admissibility of digital evidence, such as the *Daubert* standard in the United States 41 or general rules of evidence globally.39  
Legal standards require that digital evidence be:

* **Authentic:** The evidence can be proven to be from the source it claims.39 The TML log's inclusion of model versions and verified operator IDs meets this test.  
* **Integral:** The evidence is proven to be unchanged from the moment it was captured.39 The Hybrid Shield's cryptographic anchoring provides *testable, verifiable, and peer-reviewable* 41 mathematical proof of integrity.  
* **Traceable:** All interactions with the file are logged, establishing a clear chain of custody.39 The Moral Trace Log *is* the chain of custody for the decision itself, recording every step from initial prompt to State 0 pause to final human determination.

By meeting these standards, a TML-Grade Log is admissible as a "record of regularly conducted activity" 42 and provides regulators and courts with the legally defensible, non-repudiable evidence required for enforcement.

## **7.0 Conclusion: Planetary Stewardship and Intergenerational Accountability**

The UNESCO *Recommendation on the Ethics of Artificial Intelligence* provides the world with a vital consensus on the ethical principles that must guide AI. Ternary Moral Logic (TML) provides the missing architectural layer to *enforce* those principles. By translating abstract values into codified mandates and high-level principles into verifiable system-level triggers, TML bridges the critical gap from aspiration to auditable compliance.  
The TML framework, with its Sacred Pause, Moral Trace Logs, and Hybrid Shield, supplies the technical mechanisms for the transparency, accountability, and human oversight that UNESCO demands. It furnishes regulators with the forensically-sound evidence they need for governance and provides a pathway for the "effective remedy" required for victims of algorithmic harm.  
By embedding the 46+ canonical instruments of human rights and environmental law into an architecture that produces immutable, legally-admissible records, TML provides a technical foundation for true *intergenerational accountability*.43 It ensures that future generations will not have to guess at the ethical reasoning of our foundational AI systems; they will have the *logs* to audit our commitment to *planetary stewardship*.43

## **8.0 Citations**

### **8.1 Core Recommendation**

UNESCO. (2021). *Recommendation on the Ethics of Artificial Intelligence*. Paris: UNESCO. 1

### **8.2 Canonical Human Rights Instruments (Selection of 26+)**

* Universal Declaration of Human Rights (1948) 19  
* International Convention on the Elimination of All Forms of Racial Discrimination (ICERD) (1965) 18  
* International Covenant on Civil and Political Rights (ICCPR) (1966) 18  
* International Covenant on Economic, Social and Cultural Rights (ICESCR) (1966) 18  
* Convention on the Elimination of All Forms of Discrimination against Women (CEDAW) (1979) 18  
* Convention against Torture and Other Cruel, Inhuman or Degrading Treatment or Punishment (CAT) (1984) 18  
* Convention on the Rights of the Child (CRC) (1989) 18  
* International Convention on the Protection of the Rights of All Migrant Workers and Members of Their Families (ICMW) (1990) 18  
* Vienna Declaration and Programme of Action (1993) 19  
* Beijing Declaration and Platform for Action (1995) 19  
* Declaration of Human Duties and Responsibilities (UNESCO, 1998\) 19  
* Universal Declaration on Cultural Diversity (UNESCO, 2001\) 19  
* Convention on the Rights of Persons with Disabilities (CRPD) (2006) 18  
* International Convention for the Protection of All Persons from Enforced Disappearance (CPED) (2006) 18  
* Declaration on the Rights of Indigenous Peoples (2007) 19  
* Declaration on the Rights of Disabled Persons (1975) 19  
* Declaration on the Right to Development (1986) 19  
* (And other relevant regional charters and conventions)

### **8.3 Canonical Earth Protection Instruments (Selection of 20+)**

* Convention on Wetlands of International Importance (Ramsar Convention) (1971) 21  
* Convention on International Trade in Endangered Species of Wild Fauna and Flora (CITES) (1973) 20  
* Convention on the Conservation of Migratory Species of Wild Animals (Bonn Convention) (1979) 20  
* Convention on the Conservation of European Wildlife and Natural Habitats (Bern Convention) (1979) 21  
* United Nations Convention on the Law of the Sea (UNCLOS) (1982) 21  
* Vienna Convention for the Protection of the Ozone Layer (1985) and its Montreal Protocol (1987) 20  
* Basel Convention on the Control of Transboundary Movements of Hazardous Wastes (1989) 20  
* Convention on Environmental Impact Assessment in a Transboundary Context (Espoo Convention) (1991) 21  
* Convention on Biological Diversity (CBD) (1992) 20  
* United Nations Framework Convention on Climate Change (UNFCCC) (1992) 21  
* United Nations Convention to Combat Desertification (UNCCD) (1994) 21  
* Bamako Convention on the Ban of the Import into Africa and the Control of Transboundary Movement of Hazardous Wastes (1991) 20  
* Rotterdam Convention on the Prior Informed Consent Procedure (1998) 20  
* Stockholm Convention on Persistent Organic Pollutants (2001) 20  
* Framework Convention on the Protection and Sustainable Development of the Carpathians (Carpathian Convention) (2003) 20  
* Aichi Biodiversity Targets (2011) 22  
* Minamata Convention on Mercury (2013) 20  
* Paris Agreement (2015) 21  
* (And other key regional seas conventions and agreements: Abidjan, Barcelona, Cartagena, Nairobi, Tehran) 20

### **8.4 Other Sources**

* 4

#### **Works cited**

1. Ethics of Artificial Intelligence | UNESCO, accessed November 11, 2025, [https://www.unesco.org/en/artificial-intelligence/recommendation-ethics](https://www.unesco.org/en/artificial-intelligence/recommendation-ethics)  
2. Recommendation on the ethics of artificial intelligence, accessed November 11, 2025, [https://digitallibrary.un.org/record/4062376](https://digitallibrary.un.org/record/4062376)  
3. UNESCO Recommendation on the ethics of artificial intelligence | Digital Watch Observatory, accessed November 11, 2025, [https://dig.watch/resource/unesco-recommendation-on-the-ethics-of-artificial-intelligence](https://dig.watch/resource/unesco-recommendation-on-the-ethics-of-artificial-intelligence)  
4. Ternary Moral Logic (TML) \- Ethical AI Framework, accessed November 11, 2025, [https://fractonicmind.github.io/TernaryMoralLogic/](https://fractonicmind.github.io/TernaryMoralLogic/)  
5. Auditable AI by Design: How TML Turns Governance into Operational Fact \- Medium, accessed November 11, 2025, [https://medium.com/@leogouk/auditable-ai-by-design-how-tml-turns-governance-into-operational-fact-37fd73e7b77e](https://medium.com/@leogouk/auditable-ai-by-design-how-tml-turns-governance-into-operational-fact-37fd73e7b77e)  
6. FractonicMind/TernaryLogic: Ternary Logic enforces ... \- GitHub, accessed November 11, 2025, [https://github.com/FractonicMind/TernaryLogic](https://github.com/FractonicMind/TernaryLogic)  
7. Draft text of the UNESCO Recommendation on the Ethics of Artificial Intelligence, accessed November 11, 2025, [https://unesdoc.unesco.org/ark:/48223/pf0000378426](https://unesdoc.unesco.org/ark:/48223/pf0000378426)  
8. Final report on the draft text of the Recommendation on the Ethics of Artificial Intelligence, accessed November 11, 2025, [https://unesdoc.unesco.org/ark:/48223/pf0000376131](https://unesdoc.unesco.org/ark:/48223/pf0000376131)  
9. Outcome document: first draft of the Recommendation on the Ethics of Artificial Intelligence, accessed November 11, 2025, [https://unesdoc.unesco.org/ark:/48223/pf0000373434](https://unesdoc.unesco.org/ark:/48223/pf0000373434)  
10. Recommendation on the Ethics of Artificial Intelligence ... \- Naavi.org, accessed November 11, 2025, [https://www.naavi.org/uploads\_wp/2023/Recommendation%20on%20the%20Ethics%20of%20Artificial%20Intelligence%20-%20UNESCO%20Digital%20Library.pdf](https://www.naavi.org/uploads_wp/2023/Recommendation%20on%20the%20Ethics%20of%20Artificial%20Intelligence%20-%20UNESCO%20Digital%20Library.pdf)  
11. Evaluation of Document Similarity between Corporate AI Ethics Guideline and UNESCO's AI Ethics Recommendation, accessed November 11, 2025, [https://ifi.u-tokyo.ac.jp/en/wp-content/uploads/2023/10/WP028.pdf](https://ifi.u-tokyo.ac.jp/en/wp-content/uploads/2023/10/WP028.pdf)  
12. Principles of transparency and explainability in the processing of personal data in artificial intelligence \- General Assembly \- the United Nations, accessed November 11, 2025, [https://docs.un.org/en/A/78/310](https://docs.un.org/en/A/78/310)  
13. Recommendation on the Ethics of Artificial Intelligence \- Legal Affairs \- UNESCO, accessed November 11, 2025, [https://www.unesco.org/en/legal-affairs/recommendation-ethics-artificial-intelligence](https://www.unesco.org/en/legal-affairs/recommendation-ethics-artificial-intelligence)  
14. The Standard We Need Before AGI Arrives | by Lev Goukassian | TernaryMoralLogic, accessed November 11, 2025, [https://medium.com/ternarymorallogic/the-standard-we-need-before-agi-arrives-1b3bf03d8163](https://medium.com/ternarymorallogic/the-standard-we-need-before-agi-arrives-1b3bf03d8163)  
15. How a Terminal Diagnosis Inspired a New Ethical AI System \- Hackernoon, accessed November 11, 2025, [https://hackernoon.com/how-a-terminal-diagnosis-inspired-a-new-ethical-ai-system](https://hackernoon.com/how-a-terminal-diagnosis-inspired-a-new-ethical-ai-system)  
16. How Ternary Moral Logic is Teaching AI to Think, Feel, and Hesitate \- Medium, accessed November 11, 2025, [https://medium.com/ternarymorallogic/beyond-binary-how-ternary-moral-logic-is-teaching-ai-to-think-feel-and-hesitate-73de201e084e](https://medium.com/ternarymorallogic/beyond-binary-how-ternary-moral-logic-is-teaching-ai-to-think-feel-and-hesitate-73de201e084e)  
17. Recommendation on the Ethics of Artificial Intelligence \- UNESCO Digital Library, accessed November 11, 2025, [https://unesdoc.unesco.org/ark:/48223/pf0000381137](https://unesdoc.unesco.org/ark:/48223/pf0000381137)  
18. The Core International Human Rights Instruments and their ... \- ohchr, accessed November 11, 2025, [https://www.ohchr.org/en/core-international-human-rights-instruments-and-their-monitoring-bodies](https://www.ohchr.org/en/core-international-human-rights-instruments-and-their-monitoring-bodies)  
19. International human rights instruments \- Wikipedia, accessed November 11, 2025, [https://en.wikipedia.org/wiki/International\_human\_rights\_instruments](https://en.wikipedia.org/wiki/International_human_rights_instruments)  
20. Secretariats and Conventions (MEAs) \- UNEP, accessed November 11, 2025, [https://www.unep.org/about-un-environment/why-does-un-environment-matter/secretariats-and-conventions](https://www.unep.org/about-un-environment/why-does-un-environment-matter/secretariats-and-conventions)  
21. List of international environmental agreements \- Wikipedia, accessed November 11, 2025, [https://en.wikipedia.org/wiki/List\_of\_international\_environmental\_agreements](https://en.wikipedia.org/wiki/List_of_international_environmental_agreements)  
22. Multilateral Environmental Agreements \- One Planet network, accessed November 11, 2025, [https://www.oneplanetnetwork.org/SDG-12/multilateral-environmental-agreements](https://www.oneplanetnetwork.org/SDG-12/multilateral-environmental-agreements)  
23. Multilateral Environmental Agreements.pdf \- Organization of American States, accessed November 11, 2025, [http://www.oas.org/dsd/tool-kit/Documentos/MOduleII/Multilateral%20Environmental%20Agreements.pdf](http://www.oas.org/dsd/tool-kit/Documentos/MOduleII/Multilateral%20Environmental%20Agreements.pdf)  
24. Multilateral Environmental Agreements (MEAs) \- Children and Youth Major Group to UNEP (CYMG), accessed November 11, 2025, [https://www.cymgenv.net/meas-youth](https://www.cymgenv.net/meas-youth)  
25. Bias vs Fairness vs Explainability in AI \- Take Control of ML and AI Complexity \- Seldon, accessed November 11, 2025, [https://www.seldon.io/bias-vs-fairness-vs-explainability-in-ai/](https://www.seldon.io/bias-vs-fairness-vs-explainability-in-ai/)  
26. How to Detect and Prevent AI Bias Before Damage Occurs | Galileo, accessed November 11, 2025, [https://galileo.ai/blog/ai-bias-machine-learning-fairness](https://galileo.ai/blog/ai-bias-machine-learning-fairness)  
27. Unmasking bias in artificial intelligence: a systematic review of bias detection and mitigation strategies in electronic health record-based models \- PMC \- NIH, accessed November 11, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC11031231/](https://pmc.ncbi.nlm.nih.gov/articles/PMC11031231/)  
28. All that glitters is not gold: trustworthy and ethical AI principles \- PMC \- NIH, accessed November 11, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC9667859/](https://pmc.ncbi.nlm.nih.gov/articles/PMC9667859/)  
29. CSET \- A Matrix for Selecting Responsible AI Frameworks \- Center for Security and Emerging Technology, accessed November 11, 2025, [https://cset.georgetown.edu/wp-content/uploads/CSET-A-Matrix-for-Selecting-Responsible-AI-Frameworks.pdf](https://cset.georgetown.edu/wp-content/uploads/CSET-A-Matrix-for-Selecting-Responsible-AI-Frameworks.pdf)  
30. Building a Responsible AI Framework: 5 Key Principles for Organizations \- Professional & Executive Development, accessed November 11, 2025, [https://professional.dce.harvard.edu/blog/building-a-responsible-ai-framework-5-key-principles-for-organizations/](https://professional.dce.harvard.edu/blog/building-a-responsible-ai-framework-5-key-principles-for-organizations/)  
31. Policymaking in the Pause \- Future of Life Institute, accessed November 11, 2025, [https://futureoflife.org/wp-content/uploads/2023/04/FLI\_Policymaking\_In\_The\_Pause.pdf](https://futureoflife.org/wp-content/uploads/2023/04/FLI_Policymaking_In_The_Pause.pdf)  
32. AI Ethicist Addresses Safety and Oversight Concerns | Syracuse University Today, accessed November 11, 2025, [https://news.syr.edu/2023/03/30/ai-ethicist-addresses-safety-and-oversight-concerns/](https://news.syr.edu/2023/03/30/ai-ethicist-addresses-safety-and-oversight-concerns/)  
33. Don't pause AI development, prioritize ethics instead \- IBM, accessed November 11, 2025, [https://www.ibm.com/think/insights/dont-pause-ai-development-prioritize-ethics-instead](https://www.ibm.com/think/insights/dont-pause-ai-development-prioritize-ethics-instead)  
34. Readiness Assessment Methodology | Global AI Ethics and Governance Observatory, accessed November 11, 2025, [https://www.unesco.org/ethics-ai/en/ram](https://www.unesco.org/ethics-ai/en/ram)  
35. UNESCO to support more than 50 countries in designing an Ethical AI Policy this year, accessed November 11, 2025, [https://www.unesco.org/en/articles/unesco-support-more-50-countries-designing-ethical-ai-policy-year](https://www.unesco.org/en/articles/unesco-support-more-50-countries-designing-ethical-ai-policy-year)  
36. Procurement and Contract Management Handbook \- Texas Health and Human Services, accessed November 11, 2025, [https://www.hhs.texas.gov/sites/default/files/documents/pcs-procurement-contract-management-handbook.pdf](https://www.hhs.texas.gov/sites/default/files/documents/pcs-procurement-contract-management-handbook.pdf)  
37. Guide to Computer Security Log Management \- NIST Technical Series Publications, accessed November 11, 2025, [https://nvlpubs.nist.gov/nistpubs/legacy/sp/nistspecialpublication800-92.pdf](https://nvlpubs.nist.gov/nistpubs/legacy/sp/nistspecialpublication800-92.pdf)  
38. Recommended Practice: Creating Cyber Forensics Plans for Control Systems \- CISA, accessed November 11, 2025, [https://www.cisa.gov/sites/default/files/recommended\_practices/Forensics\_RP.pdf](https://www.cisa.gov/sites/default/files/recommended_practices/Forensics_RP.pdf)  
39. Admissibility of Digital Evidence: a definitive guide \- TrueScreen, accessed November 11, 2025, [https://truescreen.io/admissibility-of-digital-evidence/](https://truescreen.io/admissibility-of-digital-evidence/)  
40. Digital Forensics Investigation Jurisprudence: Issues of Admissibility of Digital Evidence, accessed November 11, 2025, [https://www.heraldopenaccess.us/openaccess/digital-forensics-investigation-jurisprudence-issues-of-admissibility-of-digital-evidence](https://www.heraldopenaccess.us/openaccess/digital-forensics-investigation-jurisprudence-issues-of-admissibility-of-digital-evidence)  
41. The admissibility of digital evidence from open-source forensic tools: Development of a framework for legal acceptance, accessed November 11, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC12431127/](https://pmc.ncbi.nlm.nih.gov/articles/PMC12431127/)  
42. Obtaining and Admitting Electronic Evidence \- Department of Justice, accessed November 11, 2025, [https://www.justice.gov/sites/default/files/usao/legacy/2011/11/30/usab5906.pdf](https://www.justice.gov/sites/default/files/usao/legacy/2011/11/30/usab5906.pdf)  
43. (PDF) Sustainable-Resilient Global-Local Regionalization: A World Theory, Multi-Case Exploration: Toward the Sustainable Regionalization Goals (SRGs) \- ResearchGate, accessed November 11, 2025, [https://www.researchgate.net/publication/392434054\_Sustainable-Resilient\_Global-Local\_Regionalization\_A\_World\_Theory\_Multi-Case\_Exploration\_Toward\_the\_Sustainable\_Regionalization\_Goals\_SRGs](https://www.researchgate.net/publication/392434054_Sustainable-Resilient_Global-Local_Regionalization_A_World_Theory_Multi-Case_Exploration_Toward_the_Sustainable_Regionalization_Goals_SRGs)  
44. Report of the Social and Human Sciences Commission (SHS) \- UNESCO Digital Library, accessed November 11, 2025, [https://unesdoc.unesco.org/ark:/48223/pf0000379920.page=14](https://unesdoc.unesco.org/ark:/48223/pf0000379920.page=14)  
45. Ethical Principles for Web Machine Learning \- W3C, accessed November 11, 2025, [https://www.w3.org/TR/webmachinelearning-ethics/](https://www.w3.org/TR/webmachinelearning-ethics/)  
46. Why SAP's Updated AI Ethics Policy Is Based on the Human Rights-Oriented UNESCO Recommendation, accessed November 11, 2025, [https://news.sap.com/2024/09/why-sap-updated-ai-ethics-policy-unesco-recommendation/](https://news.sap.com/2024/09/why-sap-updated-ai-ethics-policy-unesco-recommendation/)  
47. accessed December 31, 1969, [https://github.com/FractonicMind/TernaryMoralLogic/blob/main/docs/IMPLEMENTATION\_GUIDE.md](https://github.com/FractonicMind/TernaryMoralLogic/blob/main/docs/IMPLEMENTATION_GUIDE.md)  
48. accessed December 31, 1969, [https://github.com/FractonicMind/TernaryMoralLogic/blob/main/docs/QUICK\_START.md](https://github.com/FractonicMind/TernaryMoralLogic/blob/main/docs/QUICK_START.md)  
49. accessed December 31, 1969, [https://github.com/FractonicMind/TernaryLogic/blob/main/docs/General\_FAQ.md](https://github.com/FractonicMind/TernaryLogic/blob/main/docs/General_FAQ.md)  
50. accessed December 31, 1969, [https://github.com/FractonicMind/TernaryLogic/blob/main/TL\_Master\_Context.md](https://github.com/FractonicMind/TernaryLogic/blob/main/TL_Master_Context.md)  
51. accessed December 31, 1969, [https://github.com/FractonicMind/TernaryMoralLogic/blob/main/docs/earth/PROTECTION\_PRINCIPLES.md](https://github.com/FractonicMind/TernaryMoralLogic/blob/main/docs/earth/PROTECTION_PRINCIPLES.md)  
52. accessed December 31, 1969, [https://github.com/FractonicMind/TernaryMoralLogic/blob/main/docs/earth/FORBIDDEN.md](https://github.com/FractonicMind/TernaryMoralLogic/blob/main/docs/earth/FORBIDDEN.md)  
53. (UNESCO) Draft text of the recommendation on the ethics of artificial intelligence | UNECE, accessed November 11, 2025, [https://unece.org/documents/2021/09/informal-documents/unesco-draft-text-recommendation-ethics-artificial](https://unece.org/documents/2021/09/informal-documents/unesco-draft-text-recommendation-ethics-artificial)  
54. NeurIPS 2024 Papers, accessed November 11, 2025, [https://nips.cc/virtual/2024/papers.html](https://nips.cc/virtual/2024/papers.html)  
55. NeurIPS 2023 Papers, accessed November 11, 2025, [https://neurips.cc/virtual/2023/papers.html](https://neurips.cc/virtual/2023/papers.html)  
56. On-Device Language Models: A Comprehensive Review \- arXiv, accessed November 11, 2025, [https://arxiv.org/html/2409.00088v1](https://arxiv.org/html/2409.00088v1)  
57. ICLR 2025 Papers, accessed November 11, 2025, [https://iclr.cc/virtual/2025/papers.html](https://iclr.cc/virtual/2025/papers.html)  
58. Instruments & mechanisms \- ohchr, accessed November 11, 2025, [https://www.ohchr.org/en/instruments-and-mechanisms](https://www.ohchr.org/en/instruments-and-mechanisms)  
59. Human Rights Instruments | OHCHR, accessed November 11, 2025, [https://www.ohchr.org/en/instruments-listings](https://www.ohchr.org/en/instruments-listings)  
60. The Core International Human Rights Treaties \- ohchr, accessed November 11, 2025, [https://www.ohchr.org/sites/default/files/documents/publications/coretreatiesen.pdf](https://www.ohchr.org/sites/default/files/documents/publications/coretreatiesen.pdf)  
61. Ternary Moral Empathy Model from the Perspective of Intersubjective Phenomenology, accessed November 11, 2025, [https://www.mdpi.com/2076-328X/14/9/792](https://www.mdpi.com/2076-328X/14/9/792)  
62. Ternary Moral Empathy Model from the Perspective of Intersubjective Phenomenology, accessed November 11, 2025, [https://pubmed.ncbi.nlm.nih.gov/39336007/](https://pubmed.ncbi.nlm.nih.gov/39336007/)  
63. Simulating a Bias Mitigation Scenario in Large Language Models \- arXiv, accessed November 11, 2025, [https://arxiv.org/html/2509.14438v1](https://arxiv.org/html/2509.14438v1)  
64. Instruction-Tuned Language Models Exhibit Emergent Cognitive Bias \- arXiv, accessed November 11, 2025, [https://arxiv.org/html/2308.00225v2](https://arxiv.org/html/2308.00225v2)  
65. Framework for bias evaluation in large language models in healthcare settings \- PMC \- NIH, accessed November 11, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC12234702/](https://pmc.ncbi.nlm.nih.gov/articles/PMC12234702/)  
66. People see more of their biases in algorithms \- PNAS, accessed November 11, 2025, [https://www.pnas.org/doi/10.1073/pnas.2317602121](https://www.pnas.org/doi/10.1073/pnas.2317602121)  
67. Mitigating Algorithmic Bias in AI-Driven Cardiovascular Imaging for Fairer Diagnostics, accessed November 11, 2025, [https://www.mdpi.com/2075-4418/14/23/2675](https://www.mdpi.com/2075-4418/14/23/2675)  
68. Top 10 operational impacts of the EU AI Act﻿ – Obligations on nonproviders of high-risk AI systems \- IAPP, accessed November 11, 2025, [https://iapp.org/resources/article/top-impacts-eu-ai-act-obligations-non-providers-ai-systems/](https://iapp.org/resources/article/top-impacts-eu-ai-act-obligations-non-providers-ai-systems/)  
69. Article 60: Testing of High-Risk AI Systems in Real World Conditions Outside AI Regulatory Sandboxes | EU Artificial Intelligence Act, accessed November 11, 2025, [https://artificialintelligenceact.eu/article/60/](https://artificialintelligenceact.eu/article/60/)  
70. Full article: The ethics of AI or techno-solutionism? UNESCO's policy guidance on AI in education \- Taylor & Francis Online, accessed November 11, 2025, [https://www.tandfonline.com/doi/full/10.1080/01425692.2025.2502808](https://www.tandfonline.com/doi/full/10.1080/01425692.2025.2502808)  
71. Recommendation of the Council on Artificial Intelligence \- OECD Legal Instruments, accessed November 11, 2025, [https://legalinstruments.oecd.org/en/instruments/oecd-legal-0449](https://legalinstruments.oecd.org/en/instruments/oecd-legal-0449)  
72. Complete RFP 720-1721 Incident Response and Digital Forensics.pdf \- UT System, accessed November 11, 2025, [https://www.utsystem.edu/sites/default/files/documents/requests-for-proposal/RFP%3A%20%20Incident%20Response%20and%20Digital%20Forensics/Complete%20RFP%20720-1721%20Incident%20Response%20and%20Digital%20Forensics.pdf](https://www.utsystem.edu/sites/default/files/documents/requests-for-proposal/RFP%3A%20%20Incident%20Response%20and%20Digital%20Forensics/Complete%20RFP%20720-1721%20Incident%20Response%20and%20Digital%20Forensics.pdf)  
73. UNESCO Recommendation on the Ethics of Artificial Intelligence, accessed November 11, 2025, [https://www.unesco.de/assets/dokumente/Deutsche\_UNESCO-Kommission/02\_Publikationen/Publikation\_UNESCO\_Recommendation\_on\_the\_Ethics\_of\_Artificial\_Intelligence.pdf](https://www.unesco.de/assets/dokumente/Deutsche_UNESCO-Kommission/02_Publikationen/Publikation_UNESCO_Recommendation_on_the_Ethics_of_Artificial_Intelligence.pdf)  
74. Recommendation on the Ethics of Artificial Intelligence \- International Association for Promoting Geoethics, accessed November 11, 2025, [https://www.geoethics.org/\_files/ugd/5195a5\_56fc787932864ee199e73208ee6784ec.pdf?index=true](https://www.geoethics.org/_files/ugd/5195a5_56fc787932864ee199e73208ee6784ec.pdf?index=true)  
75. AI Ethics Principles, accessed November 11, 2025, [https://sdaia.gov.sa/en/SDAIA/about/Documents/ai-principles.pdf](https://sdaia.gov.sa/en/SDAIA/about/Documents/ai-principles.pdf)  
76. Digital Policy Office Ethical Artificial Intelligence Framework (Customised version for general reference by public), accessed November 11, 2025, [https://www.digitalpolicy.gov.hk/en/our\_work/data\_governance/policies\_standards/ethical\_ai\_framework/doc/Ethical\_AI\_Framework.pdf](https://www.digitalpolicy.gov.hk/en/our_work/data_governance/policies_standards/ethical_ai_framework/doc/Ethical_AI_Framework.pdf)  
77. Presenting Digital Evidence in Court | U.S. Legal Support, accessed November 11, 2025, [https://www.uslegalsupport.com/blog/presenting-digital-evidence-in-court/](https://www.uslegalsupport.com/blog/presenting-digital-evidence-in-court/)  
78. Fairness, model explainability and bias detection with SageMaker Clarify, accessed November 11, 2025, [https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-configure-processing-jobs.html](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-configure-processing-jobs.html)  
79. Bias and Unfairness in Machine Learning Models: A Systematic Review on Datasets, Tools, Fairness Metrics, and Identification and Mitigation Methods \- MDPI, accessed November 11, 2025, [https://www.mdpi.com/2504-2289/7/1/15](https://www.mdpi.com/2504-2289/7/1/15)  
80. A Value-Based Approach to AI Ethics: Accountability, Transparency, Explainability, and Usability \- Redalyc, accessed November 11, 2025, [https://www.redalyc.org/journal/5718/571880449002/html/](https://www.redalyc.org/journal/5718/571880449002/html/)  
81. Comparing Ethical AI Frameworks by Industry \- Magai, accessed November 11, 2025, [https://magai.co/comparing-ethical-ai-frameworks-by-industry/](https://magai.co/comparing-ethical-ai-frameworks-by-industry/)  
82. AI Ethics Principles in Practice: Perspectives of Designers and Developers \- arXiv, accessed November 11, 2025, [https://arxiv.org/html/2112.07467v8](https://arxiv.org/html/2112.07467v8)  
83. UNESCO Online Consultation: Ethics of Artificial Intelligence \- Global Partners Digital, accessed November 11, 2025, [https://www.gp-digital.org/wp-content/uploads/2020/08/UNESCO-Online-Consultation-Ethics-of-Artificial-Intelligence-GPD-Submission.pdf](https://www.gp-digital.org/wp-content/uploads/2020/08/UNESCO-Online-Consultation-Ethics-of-Artificial-Intelligence-GPD-Submission.pdf)
