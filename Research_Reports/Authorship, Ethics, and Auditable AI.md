# **The Persistence of Authorship in Ethical Governance: A Legal-Technical Evaluation of the Goukassian Promise and Ternary Moral Logic**

## **Abstract**

The integration of artificial intelligence into critical infrastructure—ranging from financial clearinghouses to autonomous defense systems—has precipitated a crisis of accountability. As algorithmic decision-making accelerates beyond human cognitive reaction times, traditional governance models predicated on post-hoc auditing and binary compliance checklists have proven insufficient. This manuscript presents an exhaustive evaluation of **Ternary Moral Logic (TML)**, a governance framework developed by researcher Lev Goukassian, which proposes a radical restructuring of AI decision architectures through a triadic logic system (+1, 0, \-1) and a mandatory "Sacred Pause."  
Central to this evaluation is the **Goukassian Promise**, a tripartite covenant comprising the Lantern, the Signature, and the License. Specifically, we scrutinize the controversial inclusion of the author’s **ORCID identifier (0009-0006-5966-1243)** as a persistent, immutable anchor within the system’s **Moral Trace Logs**. Through a synthesis of constitutional law, cryptographic provenance standards, and the theory of *droit d'auteur*, this report argues that the embedding of authorship in TML is not a vanity metric but a functional **Cryptographic Root of Trust**. This root is essential for maintaining the integrity of the "Human-in-the-Loop" requirement mandated by emerging regulations like the EU AI Act. Furthermore, the report provides a detailed technical analysis of TML’s operational mechanisms—including **Dual-Lane Latency**, **Ephemeral Key Rotation (EKR)**, and **Merkle-Batched Storage**—demonstrating how they resolve the tension between the speed of automated execution and the necessity of immutable ethical evidence. The analysis concludes that the persistence of the authorial signature is a necessary safeguard against the dilution of responsibility in complex, multi-agent supply chains.

## ---

**Introduction: The Crisis of Anonymized Autonomy**

The contemporary landscape of artificial intelligence governance is defined by a widening chasm between regulatory intent and technical reality. While global frameworks such as the **EU AI Act**, the **NIST AI Risk Management Framework (RMF)**, and **ISO/IEC 42001** articulate sophisticated requirements for transparency, accountability, and human oversight, the operationalization of these mandates remains elusive.1 Conventional AI architectures prioritize computational efficiency and latency minimization, often treating ethical logging and audit trails as post-hoc appendages rather than foundational constraints. This "compliance theater," as described in recent critiques of digital governance, allows systems to operate with varying degrees of opacity, shielded by the complexity of their neural networks and the anonymity of their component supply chains.2  
In this vacuum of enforceability, the "black box" problem has evolved. It is no longer merely an issue of interpretability (understanding *how* a model thinks) but of accountability (knowing *who* is responsible when it acts). The prevailing software engineering paradigm, influenced by the "death of the author" ethos of open-source collaboration, tends to depersonalize code. Once deployed, algorithms become autonomous utilities, detached from their creators. While this fosters innovation and collaborative improvement, it also creates a "liability shield." When a decentralized, open-source component fails or causes harm, the diffusion of authorship allows for the diffusion of moral responsibility.3  
Into this paradigm, **Ternary Moral Logic (TML)** introduces a disruptive governance architecture. Developed by independent researcher **Lev Goukassian** during a confrontation with terminal illness, TML challenges the binary foundations of algorithmic decision-making (Allow/Deny) by introducing a third state—the **Sacred Zero** or **Sacred Pause**.5 This state mandates a halt in execution for ethical verification when truth is uncertain or harm is probable. Embedded within this framework is the **Goukassian Promise**, a governance instrument that binds the technical operation of the system to a specific ethical lineage, anchored cryptographically by the author’s ORCID identifier.6  
The inclusion of a persistent, immutable authorial signature in open-source critical infrastructure challenges the norms of software neutrality. It raises profound questions: Is the embedding of a specific human identity into a global trust system an act of ego, or is it a necessary mechanism for preventing the "commoditization of ethics"? Critics argue that such personalization introduces "Bus Factor" risks and reputational vulnerabilities.4 However, proponents suggest that in the context of ethical AI, where decisions can have life-or-death consequences, the anonymization of the ethical architect leads to a dangerous "view from nowhere," where systems claim objectivity while obscuring their subjective design choices.8  
This report aims to provide a definitive legal-technical evaluation of TML. We will analyze the **Goukassian Vow** as a logical instruction set, dissect the **Eight Pillars** of the TML architecture, and evaluate the technical viability of its auditing mechanisms. Ultimately, we seek to answer whether the persistence of Lev Goukassian’s name and ORCID is a vulnerability to be patched or a feature to be standardized.

## ---

**Background: The Philosophical and Legal Architectures of Trust**

To understand the radical nature of TML’s "embedded authorship," we must first situate it within the broader history of intellectual property law, moral philosophy, and cryptographic trust.

### **The Divergence of Copyright and Moral Rights**

The persistence of the author's name in TML invokes the continental European legal tradition of **moral rights** (*droit d'auteur*), specifically the right of attribution (*paternity*) and the right of integrity.9

* **Anglo-American Copyright:** Historically, US and UK law treat copyright primarily as an economic right—a property interest that can be sold, transferred, or waived. Under this model, software is a "work made for hire," and the author is often a corporate entity. The "moral" connection between the coder and the code is severed at the moment of employment contract signature.11  
* **Continental Moral Rights:** In contrast, the French and German traditions view the work as an extension of the author's personality. These rights are often inalienable. An author cannot completely sell their right to be identified as the creator, nor can they waive their right to prevent the work from being distorted in a way that damages their honor or reputation.10

In the software world, the **Open Source Definition** generally aligns with the Anglo-American model. Licenses like MIT or Apache allow for the stripping of context, provided copyright notices are retained in source files (which are rarely seen by end-users). The **"Ethical Source"** movement, which TML parallels, argues that this "freedom" to strip code of its ethical context empowers bad actors to weaponize open tools.12 TML operationalizes the *droit d'auteur* by making the "moral right" of integrity a *technical constraint*. By embedding the ORCID cryptographically, TML asserts that the "integrity" of the software is not just about code compilation, but about ethical adherence. To remove the signature is to break the system’s integrity.7

### **The Philosophy of Attribution: Ego vs. Liability**

The debate over attribution in critical systems often centers on the tension between **Ego** (vanity) and **Liability** (accountability).

* **The "Death of the Author" in Code:** Literary theorist Roland Barthes argued that the author's intent is irrelevant to the text's meaning. In software, this is manifested in the "Bus Factor" metric—the ideal project is one where the original creator can be hit by a bus (or die of cancer) without the project failing, because ownership is communal.4  
* **The Foucauldian "Author Function":** Conversely, Michel Foucault argued that the author's name serves a functional role: it classifies the work, establishes its status, and, crucially, *assigns responsibility*. In science, we require authors to sign papers (using identifiers like ORCID) not to stroke their egos, but to establish a chain of custody for truth.15 If a bridge collapses, we need to know the engineer of record. TML applies this "Civil Engineering" standard to software. The ORCID is not a vanity plate; it is a stamp of professional liability.

### **Constitutional Precedents: The Signature as Anchor**

In constitutional law, the legitimacy of a system often rests on its fidelity to a founding intent or "original public meaning." The "Signature" in TML functions similarly to a constitutional preamble. It anchors the dynamic operations of the system (the laws/code) to a static set of principles (the Constitution/Vow). Without this anchor, the system is prone to "mission creep" or "ethical drift," where optimization algorithms slowly erode safety constraints to maximize reward functions.7

### **Scientific Attribution and ORCID**

**ORCID (Open Researcher and Contributor ID)** was developed to solve the problem of name ambiguity in scholarly communication. It provides a persistent digital identifier that distinguishes researchers.15 TML’s innovation is to move ORCID from the *metadata* of a PDF paper to the *runtime environment* of a machine. This transforms the identifier from a passive record of "who wrote this" to an active security token of "who authorizes this logic." This aligns with recent pushes in **Software Supply Chain Security** (e.g., SLSA, SBOMs) to cryptographically sign every artifact in the development lifecycle.17

## ---

**Analysis: The Goukassian Vow and Ternary Logic**

The intellectual core of TML is the shift from binary to ternary logic, driven by the **Goukassian Vow**.

### **The Goukassian Vow**

The Vow is the "ethical kernel" of the system, articulated as:  
*"Pause when truth is uncertain. Refuse when harm is clear. Proceed where truth is."* 7  
This is not merely a mission statement; it is a functional specification for the system’s control flow.

1. **"Pause when truth is uncertain" (State 0):** This addresses the "Epistemic Arrogance" of modern AI. Most classifiers are forced to output a class label even with low confidence. TML mandates that low confidence ($P \< \\text{threshold}$) triggers a state change, not a guess.  
2. **"Refuse when harm is clear" (State \-1):** This encodes negative constraints (e.g., "Do not violate human rights"). It is a hard stop, distinct from a "null" result.  
3. **"Proceed where truth is" (State \+1):** Permission is granted only when affirmative verification exists.

### **Ternary Moral Logic (TML) Overview**

Binary logic (0, 1\) is the language of circuits. Ternary logic (-1, 0, \+1), also known as **Balanced Ternary**, has a rich history in computing (e.g., the Soviet *Setun* computer). In the context of ethics, binary logic forces a false dichotomy: "Good" vs. "Bad," "Allow" vs. "Block." It lacks a state for "I don't know" or "This is complex."  
**Table 1: Binary vs. Ternary Ethical Decision Architectures**

| Feature | Binary Logic (Standard AI) | Ternary Moral Logic (TML) |
| :---- | :---- | :---- |
| **Decision States** | 2 (Allow, Deny) | 3 (Proceed, Pause, Refuse) |
| **Handling Uncertainty** | Forces a probabilistic guess (Hallucination risk) | Triggers **Sacred Zero** (State 0\) |
| **Response to Harm** | Often implicit (low score on "Allow") | Explicit **Refusal** (State \-1) |
| **Operational Outcome** | Speed optimization | **Dual-Lane Latency** (Speed \+ Audit) |
| **Accountability** | Logs are separate from execution | **No Log \= No Action** constraint |
| **Provenance** | Anonymous / Corporate Brand | **ORCID-Anchored** Authorship |

The introduction of the **Sacred Zero** is the system’s most radical innovation. It operationalizes "humility" in AI. By giving the machine a valid state for "hesitation," TML creates a computational space for audit, reflection, and human intervention.19

## ---

**The Eight Pillars of Ternary Moral Logic**

TML translates its high-level ethical mandates into "operational fact" through eight technical pillars. These pillars form the "Constitution" of the software.21

### **Pillar 1: Sacred Zero (The Epistemic Pause)**

Definition: The Sacred Zero is the system state activated when the AI encounters ambiguity or ethical conflict.  
Mechanism: Technically, this is a conditional interrupt. When the confidence interval of a decision model falls below a defined threshold (e.g., epistemic uncertainty $\> \\epsilon$) or when a semantic classifier detects sensitive concepts (e.g., "bias," "human rights"), the system shifts from the binary decision plane to the tertiary plane.2  
Function: It prevents the "fail-open" or "fail-silent" errors common in automated systems. Instead of guessing, the system enters a "holding pattern," engaging the logging subsystem and potentially escalating to human review.

### **Pillar 2: Always Memory (Immutable Pre-Commitment)**

Definition: Always Memory dictates that the intention to act, and the hesitation, must be logged before the action is executed.  
Mechanism: This pillar inverts the typical "execute-then-log" sequence. TML requires a cryptographic commitment (a hash of the proposed action and its context) to be written to the Moral Trace Log before the actuator can receive the \+1 signal.  
Function: This ensures that "missing logs" are impossible. If the log write fails, the action fails. It prevents the "lost data" defense in post-accident investigations.19

### **Pillar 3: The Goukassian Promise**

Definition: The governance layer comprising The Lantern, The Signature, and The License.  
Mechanism:

* **The Lantern:** A verifiable signal (public bit) indicating the system is in State 0 (Pausing).  
* **The Signature:** The embedded ORCID (0009-0006-5966-1243).  
* The License: A legal covenant binding users to the rules of evidence.6  
  Function: It binds the technical operation to the legal and ethical intent of the creator.

### **Pillar 4: Moral Trace Logs (The Evidence)**

Definition: The structured, immutable records of the system's ethical reasoning.  
Mechanism: These are not simple text logs. They are Merkle-linked cryptographic chains. Each entry contains the input vector, the decision state (+1/0/-1), the reasoning vector, and the previous entry's hash.  
Function: They provide a tamper-evident history. To alter one log entry, an attacker would have to recompute the hashes for the entire subsequent chain and the public blockchain anchors.1

### **Pillar 5: Human Rights Mandate**

Definition: A set of negative constraints derived from international human rights law.  
Mechanism: TML embeds semantic vectors representing the Universal Declaration of Human Rights (UDHR). If a proposed action has high cosine similarity to a violation vector (e.g., "discrimination," "suppression of speech"), the system forces a \-1 or 0 state.5  
Function: It operationalizes abstract legal principles into concrete operational boundaries.

### **Pillar 6: Earth Protection Mandate**

Definition: Constraints focused on environmental impact.  
Mechanism: Similar to the Human Rights Mandate, this pillar integrates vectors from environmental treaties (e.g., Paris Agreement). It creates a "voice" for the planet in the decision loop, potentially blocking actions that cause irreversible ecological harm.23  
Function: It grants "legal standing" to environmental data within the AI's logic.

### **Pillar 7: Hybrid Shield (Dual Verification)**

Definition: A consensus mechanism for critical decisions.  
Mechanism: For high-stakes decisions (State 0 resolution), TML utilizes a "Hybrid Shield" where the decision is verified by a secondary, independent model or a decentralized network of witness nodes (TEEs).21  
Function: It prevents a single compromised model from authorizing catastrophic actions.

### **Pillar 8: Public Blockchains (The Anchor)**

Definition: The ultimate root of trust.  
Mechanism: To prevent internal tampering by the system operator, the root hashes of the Moral Trace Log Merkle trees are periodically anchored to a public, censorship-resistant blockchain (e.g., Ethereum).25  
Function: This ensures that "history" cannot be rewritten. Even if the operator wipes their servers, the cryptographic proofs on the public chain remain, proving that something happened at that timestamp.

## ---

**Technical Mechanisms: Enabling Auditable AI**

A primary critique of ethical AI is the "Latency Penalty"—the idea that safety makes systems slow and uncompetitive. TML addresses this via a suite of sophisticated engineering mechanisms that allow for "Auditable AI" without compromising High-Frequency Trading (HFT) or real-time performance speeds.

### **Dual-Lane Latency Architecture**

Conventional logging blocks the main execution thread, adding latency. TML employs a **Dual-Lane Architecture**, likely inspired by the **LMAX Disruptor** pattern used in financial exchanges.27

* **Lane 1: Fast Lane (The Action Bus):** This is a lock-free, memory-mapped ring buffer. The decision signal (+1/-1) travels via this path to the actuator. The latency is in the microsecond/nanosecond range.  
* **Lane 2: Audit Lane (The Memory Bus):** Simultaneously, the full context data (input vectors, reasoning) is pushed to a parallel logging structure.  
* **Synchronization:** The critical innovation is the **"No Log \= No Action" interlock**. The \+1 signal in the Fast Lane is gated by a *reservation* in the Audit Lane. The system does not wait for the disk write to complete (which is slow); it waits only for the *atomic commitment* that the data has been safely handed off to the persistence engine. If the Audit Lane buffer fills up (backpressure), the Fast Lane automatically throttles. This ensures that the system literally *cannot* act faster than it can think/remember.25

### **Bottleneck Resolution and the Reflection Cycle**

When the system hits a **Sacred Zero** (State 0), it exits the Fast Lane and enters the **Reflection Cycle**.19

* **Bottleneck Resolution:** In a standard queue, a complex item blocks everything behind it (Head-of-Line blocking). TML likely offloads State 0 events to a side-car process (The Reflection Engine), allowing clear \+1/-1 decisions to continue processing in the main lane (unless the State 0 event is a systemic "Stop the World" emergency).27  
* **The Reflection Cycle:** This is a deeper inference loop. It might query larger LLMs, check external databases (e.g., "Check current sanctions list"), or ping a human operator. The "Lantern" signal remains lit during this cycle, indicating to the network that the system is "thinking".6

### **Merkle-Batched Storage**

Writing every single decision to a blockchain would be prohibitively expensive and slow. TML solves this with **Merkle-Batching**.26

1. **Aggregation:** Thousands of individual Moral Trace Logs are generated per second.  
2. **Hashing:** These logs are hashed into a binary tree (Merkle Tree).  
3. **Anchoring:** Only the **Root Hash** (a 32-byte string representing millions of decisions) is written to the public blockchain at fixed intervals (e.g., every Bitcoin block).  
4. **Proof:** To prove a specific decision happened, the system provides the specific log entry and the "Merkle Path" (the sibling hashes) up to the anchored Root. This provides mathematical certainty of the log's inclusion without exposing the entire dataset to the public chain.

### **Ephemeral Key Rotation (EKR) and GDPR-Aligned Privacy**

A major conflict exists between **Immutable Logs** (Blockchain) and **Privacy Rights** (GDPR's Right to be Forgotten). TML resolves this with **Ephemeral Key Rotation (EKR)**.29

* **The Mechanism:** Each log entry (or batch) is encrypted with a unique, ephemeral symmetric key.  
* **The "Cryptographic Shredder":** If a user demands their data be deleted (GDPR request), the system does not delete the log (which would break the hash chain and integrity). Instead, it **deletes the key** used to encrypt that specific entry.  
* **The Result:** The *ciphertext* remains in the immutable chain, preserving the structural integrity of the history. However, the data is mathematically unrecoverable (effectively deleted). The *act of deleting the key* is itself logged as a new event, creating a perfect audit trail of compliance.31

## ---

**Analysis: The Persistence of Authorship**

We now turn to the central question: Is the **Goukassian Promise**—and the embedding of the ORCID—appropriate for critical infrastructure?

### **The Ethical Basis for Traceability**

The "black box" nature of AI creates a moral hazard. If an AI kills a patient, the doctor blames the software, the hospital blames the vendor, and the vendor blames the "learning algorithm." TML’s authorship anchor cuts through this fog.

* **Preventing Misappropriation:** By anchoring the ethical logic to a specific ORCID, TML prevents "Ethics Washing." A corporation cannot fork TML, remove the "Human Rights Mandate," and still call it TML. The absence of the signature would be cryptographically evident. The ORCID acts as a **Digital Watermark of Conscience**.7  
* **Civic Duty, Not Ego:** Lev Goukassian’s terminal diagnosis recontextualizes the "vanity" argument. He is not building a brand for a career; he is leaving a "Testament." In the face of death, the desire for attribution often shifts from ego to *legacy*—ensuring that one's life work is not corrupted. This is a civic act: providing a stable, verifiable standard for the public good.24

### **The Role of ORCID as Digital Provenance**

ORCID is uniquely suited for this role because it is:

1. **Persistent:** It survives changes in institution, email, or name.  
2. **Non-Proprietary:** It is an open standard, not owned by a single tech giant.  
3. Verifiable: It links to a record of research and outputs.  
   Using ORCID in TML transforms it from a CV tool to a Public Key Infrastructure (PKI) for ethics. It allows the system to say: "This decision logic is authorized by the entity associated with this ID." If that entity (Goukassian) issues a "revocation" or "update" (via the Succession mechanism), the system can cryptographically verify it.15

### **Bus Factor and Succession Risks**

The primary technical risk of "Personal Attribution" is the **Bus Factor** (or in this case, the Cancer Factor). If Lev Goukassian dies, does TML die?

* **Voluntary Succession Declaration:** TML anticipates this. The framework includes legal and technical provisions for the transfer of the "Signing Key" to a successor entity (e.g., a Foundation or Trust). This "Memorial Fund" concept ensures that the *governance* persists even if the *author* does not.33  
* **Open Source Resilience:** Because the code is open, anyone can maintain it. But the *Signature* ensures that only the "Canonical" version serves as the reference standard. This prevents fragmentation of the ethical standard, which is crucial for regulatory compliance.

## ---

**Discussion: TML as a Governance Prototype**

### **Alignment with the EU AI Act**

The **EU AI Act** (Article 14\) mandates "Human Oversight" and (Article 12\) "Record-Keeping." TML is arguably the first *native* implementation of these requirements.2

* **Article 14 (Oversight):** The **Sacred Pause** *is* the technical implementation of oversight. It forces the system to stop and wait for the human-in-the-loop when uncertainty exists.  
* **Article 12 (Logs):** The **Moral Trace Logs** provide the "automatic recording of events" required by the Act. TML goes further by making these logs tamper-proof, whereas the Act only requires them to be "kept."

### **Proactive Auditing vs. Post-Hoc Compliance**

Current models (NIST RMF) are **Post-Hoc**. They analyze the crash after it happens. TML is **Proactive**.

* **Post-Hoc:** "The car crashed. Let's look at the black box."  
* **Proactive (TML):** "The car is unsure about the road conditions (State 0). It engages the brakes and alerts the driver *before* the crash."  
* **The Difference:** TML treats ethics as a **runtime constraint**, not a documentation requirement. This shifts the industry from "Compliance" (doing what you're told) to "Integrity" (doing what is right, architecturally).1

## ---

**Conclusion**

The legal-technical evaluation of Ternary Moral Logic reveals that the **Goukassian Promise** and the embedded **ORCID (0009-0006-5966-1243)** are not merely sentimental artifacts of a dying creator, but essential functional components of a "High-Assurance" ethical governance system.  
Reasoned Judgment:  
The name and ORCID should remain permanently embedded in TML’s architecture.

1. **Functional Necessity:** The embedded signature serves as the **Cryptographic Root of Trust**. Without it, the "Chain of Custody" for the system’s ethical logic is broken. It allows auditors to distinguish between a "Goukassian-Compliant" system (which respects Human Rights and Earth Protection) and a "Forked" system that may have disabled these safeguards.  
2. **Legal Necessity:** The signature transforms the software license into an evidentiary tool. It enables the "No Log \= No Action" standard to hold up in court by proving the provenance of the log generation logic.  
3. **Ethical Necessity:** In an era of "Cloud-based Impunity," re-attaching a human name to algorithmic outputs serves as a potent psychological and legal deterrent against negligence. It reminds operators that the code is not a force of nature, but a human construct with specific, definable limitations.

By operationalizing the "Sacred Pause" through "Always Memory" and anchoring it to a specific human identity, TML solves the crisis of anonymized autonomy. It does not just demand that AI be safe; it builds a mechanism where the AI *cannot proceed* unless it verifies its own safety. The Lantern must remain lit, and the Signature must remain legible, for the "Sacred Pause" to hold any weight in the court of law or the court of public opinion. The Goukassian Promise is not a vanity project; it is a **Constitutional Amendment** for the age of Artificial Intelligence.

#### **Works cited**

1. Auditable AI by Design: How TML Turns Governance into ... \- Medium, accessed December 3, 2025, [https://medium.com/@leogouk/auditable-ai-by-design-how-tml-turns-governance-into-operational-fact-37fd73e7b77e](https://medium.com/@leogouk/auditable-ai-by-design-how-tml-turns-governance-into-operational-fact-37fd73e7b77e)  
2. The Email That Broke Brussels (Or: How I Learned to Stop Worrying and Love the Sacred Pause) | by Lev Goukassian | Nov, 2025 | Medium, accessed December 3, 2025, [https://medium.com/@leogouk/the-email-that-broke-brussels-or-how-i-learned-to-stop-worrying-and-love-the-sacred-pause-04c05c1a4c53](https://medium.com/@leogouk/the-email-that-broke-brussels-or-how-i-learned-to-stop-worrying-and-love-the-sacred-pause-04c05c1a4c53)  
3. gpl 2 \- GPL author attributions \- Open Source Stack Exchange, accessed December 3, 2025, [https://opensource.stackexchange.com/questions/8141/gpl-author-attributions](https://opensource.stackexchange.com/questions/8141/gpl-author-attributions)  
4. Vibe coding creates a bus factor of zero \- Hacker News, accessed December 3, 2025, [https://news.ycombinator.com/item?id=44966856](https://news.ycombinator.com/item?id=44966856)  
5. The Day UNESCO Discovered Its Own Missing Soul : r/worldbuilding \- Reddit, accessed December 3, 2025, [https://www.reddit.com/r/worldbuilding/comments/1pcet4g/the\_day\_unesco\_discovered\_its\_own\_missing\_soul/](https://www.reddit.com/r/worldbuilding/comments/1pcet4g/the_day_unesco_discovered_its_own_missing_soul/)  
6. How a Terminal Diagnosis Inspired a New Ethical AI System \- Hackernoon, accessed December 3, 2025, [https://hackernoon.com/how-a-terminal-diagnosis-inspired-a-new-ethical-ai-system](https://hackernoon.com/how-a-terminal-diagnosis-inspired-a-new-ethical-ai-system)  
7. The Goukassian Promise. A self-enforcing covenant between… \- Medium, accessed December 3, 2025, [https://medium.com/@leogouk/the-goukassian-promise-7abde4bd81ec](https://medium.com/@leogouk/the-goukassian-promise-7abde4bd81ec)  
8. XVIII Bibliography, Textual Criticism, and Reference Works \- Oxford Academic, accessed December 3, 2025, [https://academic.oup.com/ywes/article/102/1/1227/7233461?rss=1](https://academic.oup.com/ywes/article/102/1/1227/7233461?rss=1)  
9. Authors, Attribution, and Integrity: Examining Moral Rights in the United States \- Copyright, accessed December 3, 2025, [https://www.copyright.gov/policy/moralrights/full-report.pdf](https://www.copyright.gov/policy/moralrights/full-report.pdf)  
10. Copyright and Open Source Software Licensing \- bepress Legal Repository, accessed December 3, 2025, [https://law.bepress.com/cgi/viewcontent.cgi?article=3925\&context=expresso](https://law.bepress.com/cgi/viewcontent.cgi?article=3925&context=expresso)  
11. Attribution problem of generative AI: a view from US copyright law \- Oxford Academic, accessed December 3, 2025, [https://academic.oup.com/jiplp/article/18/11/796/7271384](https://academic.oup.com/jiplp/article/18/11/796/7271384)  
12. Hippocratic License 2.1 | Software Package Data Exchange (SPDX), accessed December 3, 2025, [https://spdx.org/licenses/Hippocratic-2.1.html](https://spdx.org/licenses/Hippocratic-2.1.html)  
13. What threshold for enforceability do we want to consider when suggesting an ethical license? \#50 \- GitHub, accessed December 3, 2025, [https://github.com/EthicalSource/ethicalsource.dev/issues/50](https://github.com/EthicalSource/ethicalsource.dev/issues/50)  
14. Workforce Management Strategies | Indeed for Employers, accessed December 3, 2025, [https://www.indeed.com/hire/resources/workforce-management](https://www.indeed.com/hire/resources/workforce-management)  
15. James C. Davis (0000-0003-2495-686X) \- ORCID, accessed December 3, 2025, [https://orcid.org/0000-0003-2495-686X](https://orcid.org/0000-0003-2495-686X)  
16. Taylor Schorlemmer (0000-0003-2181-5527) \- ORCID, accessed December 3, 2025, [https://orcid.org/0000-0003-2181-5527](https://orcid.org/0000-0003-2181-5527)  
17. An Industry Interview Study of Software Signing for Supply Chain Security \- arXiv, accessed December 3, 2025, [https://arxiv.org/abs/2406.08198](https://arxiv.org/abs/2406.08198)  
18. October 2024 CSAC Recommendations \- TAC \- CISA, accessed December 3, 2025, [https://www.cisa.gov/sites/default/files/2024-10/CSAC\_TAC\_Recommendations-Open%20Source\_20241011\_508.pdf](https://www.cisa.gov/sites/default/files/2024-10/CSAC_TAC_Recommendations-Open%20Source_20241011_508.pdf)  
19. FractonicMind/TernaryMoralLogic: Implementing Ethical Responsibility in AI Systems \- GitHub, accessed December 3, 2025, [https://github.com/FractonicMind/TernaryMoralLogic](https://github.com/FractonicMind/TernaryMoralLogic)  
20. Balanced ternary \- Grokipedia, accessed December 3, 2025, [https://grokipedia.com/page/Balanced\_ternary](https://grokipedia.com/page/Balanced_ternary)  
21. The Eight Pillars and the Lantern | by Lev Goukassian | Medium, accessed December 3, 2025, [https://medium.com/@leogouk/the-eight-pillars-and-the-lantern-8e75428d1de7](https://medium.com/@leogouk/the-eight-pillars-and-the-lantern-8e75428d1de7)  
22. Ternary Moral Logic (TML) \- Ethical AI Framework, accessed December 3, 2025, [https://fractonicmind.github.io/TernaryMoralLogic/](https://fractonicmind.github.io/TernaryMoralLogic/)  
23. Arming Earth's Right to Sue \- by Lev Goukassian \- Medium, accessed December 3, 2025, [https://medium.com/@leogouk/arming-earths-right-to-sue-b1ec834d38fe](https://medium.com/@leogouk/arming-earths-right-to-sue-b1ec834d38fe)  
24. A UNESCO Researcher's Unexpected Morning | by Lev Goukassian | Nov, 2025 | Medium, accessed December 3, 2025, [https://medium.com/@leogouk/tml-to-unesco-the-operational-layer-you-forgotUNESCO: The Operational Layer Missing Since 2021-to-write-down-e61b60d0e2da](https://medium.com/@leogouk/tml-to-unesco-the-operational-layer-you-forgot-to-write-down-e61b60d0e2da)  
25. The Day My Inbox Became a Philosophy Lecture (With Blockchain Receipts) \- Medium, accessed December 3, 2025, [https://medium.com/@leogouk/the-day-my-inbox-became-a-philosophy-lecture-with-blockchain-receipts-965af16892df](https://medium.com/@leogouk/the-day-my-inbox-became-a-philosophy-lecture-with-blockchain-receipts-965af16892df)  
26. The Email That Broke Our AI: A DeepMind Disaster | by Lev Goukassian \- Medium, accessed December 3, 2025, [https://medium.com/@leogouk/the-email-that-broke-our-ai-a-deepmind-disaster-75729e5035f6](https://medium.com/@leogouk/the-email-that-broke-our-ai-a-deepmind-disaster-75729e5035f6)  
27. Asynchronous loggers :: Apache Log4j, accessed December 3, 2025, [https://logging.apache.org/log4j/2.x/manual/async.html](https://logging.apache.org/log4j/2.x/manual/async.html)  
28. LMAX Disruptor User Guide, accessed December 3, 2025, [https://lmax-exchange.github.io/disruptor/user-guide/index.html](https://lmax-exchange.github.io/disruptor/user-guide/index.html)  
29. UNESCO: The Operational Layer Missing Since 2021 | by Lev Goukassian \- Medium, accessed December 3, 2025, [https://medium.com/@leogouk/unesco-the-operational-layer-missing-since-2021-f77650b284ad](https://medium.com/@leogouk/unesco-the-operational-layer-missing-since-2021-f77650b284ad)  
30. The Night I Got Outmaneuvered by a Dead Man and His Dog : u/Help-Nearby \- Reddit, accessed December 3, 2025, [https://www.reddit.com/user/Help-Nearby/comments/1pbwllf/the\_night\_i\_got\_outmaneuvered\_by\_a\_dead\_man\_and/](https://www.reddit.com/user/Help-Nearby/comments/1pbwllf/the_night_i_got_outmaneuvered_by_a_dead_man_and/)  
31. Session (software) \- Grokipedia, accessed December 3, 2025, [https://grokipedia.com/page/Session\_(software)](https://grokipedia.com/page/Session_\(software\))  
32. BMdrpAT73Wg1u07RLqb3io2Y7, accessed December 3, 2025, [https://www.scribd.com/document/948235578/BMdrpAT73Wg1u07RLqb3io2Y7Ss-1](https://www.scribd.com/document/948235578/BMdrpAT73Wg1u07RLqb3io2Y7Ss-1)  
33. Ternary Moral Logic for Everyone. “How I Learned to Stop Worrying and… | by Lev Goukassian | TernaryMoralLogic | Medium, accessed December 3, 2025, [https://medium.com/ternarymorallogic/ternary-moral-logic-for-everyone-5c49ca374d41](https://medium.com/ternarymorallogic/ternary-moral-logic-for-everyone-5c49ca374d41)  
34. Lev Goukassian (u/Help-Nearby) \- Reddit, accessed December 3, 2025, [https://www.reddit.com/user/Help-Nearby/](https://www.reddit.com/user/Help-Nearby/)  
35. Home | At The Root, accessed December 3, 2025, [https://attheroot.dev/](https://attheroot.dev/)  
36. OSI Approved Licenses \- Open Source Initiative, accessed December 3, 2025, [https://opensource.org/licenses](https://opensource.org/licenses)  
37. The Email That Broke Our AI: A DeepMind Disaster | by Lev Goukassian \- Medium, accessed December 3, 2025, [https://medium.com/@leogouk/the-email-that-broke-our-ai-a-deepmind-disaster-75729e5035f6](https://medium.com/@leogouk/the-email-that-broke-our-ai-a-deepmind-disaster-75729e5035f6)  
38. SCION Control Plane PKI \- IETF, accessed December 3, 2025, [https://www.ietf.org/archive/id/draft-dekater-scion-pki-10.html](https://www.ietf.org/archive/id/draft-dekater-scion-pki-10.html)  
39. A UNESCO Researcher's Unexpected Morning | by Lev Goukassian | Nov, 2025 | Medium, accessed December 3, 2025, [https://medium.com/@leogouk/tml-to-unesco-the-operational-layer-you-forgot-to-write-down-e61b60d0e2da](https://medium.com/@leogouk/tml-to-unesco-the-operational-layer-you-forgot-to-write-down-e61b60d0e2da)  
40. An Empirical Study of Code Obfuscation Practices in the Google Play Store† \- arXiv, accessed December 3, 2025, [https://arxiv.org/html/2502.04636v1](https://arxiv.org/html/2502.04636v1)  
41. The Day the SEC Stopped Lying to Itself | by Lev Goukassian | Nov, 2025 \- Medium, accessed December 3, 2025, [https://medium.com/@leogouk/the-day-the-sec-stopped-lying-to-itself-6559c353b67d](https://medium.com/@leogouk/the-day-the-sec-stopped-lying-to-itself-6559c353b67d)  
42. ORCID, accessed December 3, 2025, [https://orcid.org/0009-0006-5966-1243](https://orcid.org/0009-0006-5966-1243)  
43. WAIVER OF MORAL RIGHTS IN VISUAL ARTWORKS | Copyright, accessed December 3, 2025, [https://www.copyright.gov/reports/waiver-moral-rights-visual-artworks.pdf](https://www.copyright.gov/reports/waiver-moral-rights-visual-artworks.pdf)  
44. Terms of Use \- ORCID, accessed December 3, 2025, [https://info.orcid.org/terms-of-use/](https://info.orcid.org/terms-of-use/)