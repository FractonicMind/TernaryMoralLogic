# Субботний вечер, который пошёл не по плану (или: Как я прочитал 49 страниц об ИИ, чтобы вы этого не делали)

Значит, сидим мы в субботу вечером — я, мой друг Коля (тоже AI-юрист, беда с нами), наши жены, в общем, культурно отдыхаем. Ресторан "La Fenice", свечи, паста, «как прошел твой день, дорогой?» — идиллия, блин.

И тут официант, милый такой парень, подходит к нашему столику и протягивает мне... конверт. Бумажный. Натуральный такой конверт, как из прошлого века. Я думал, там счет или, может, приглашение на дегустацию вин.

Открываю.

А там — документ. На сорок девять страниц.

Сорок. Девять. Страниц.

Название: «Экспертный анализ предложенного стандарта "Тройственной моральной логики" для подотчетности ИИ: правовые, технические и управленческие императивы».

Коля, который только что поднес ко рту бокал с "Бароло", замер. Жены синхронно закатили глаза — они это умеют, у них стаж.

— Это что, — говорю я, переворачивая первую страницу, — «Раздел 1: Деконструкция стандарта тройственной моральной логики»?

— Читай вслух, — прошептал Коля. У него глаза горели как у ребенка, которому пообещали два «Хогвартса» сразу.

И я начал читать.

***

Представьте себе, что у вас есть моральный компас. Но не простой, где там «север-юг», а такой, где есть три состояния: ЗАПРЕЩЕНО, РАЗРЕШЕНО и ОБЯЗАТЕЛЬНО.

— Это как в армии, — сказал Коля. — Можно, нельзя, и «ты должен, рядовой».

— Тихо, не перебивай.

Дальше идет про «Этическую прозрачность». Это, оказывается, не просто «объяснимость», а целая цепочка доказательств: какое правило сработало, какие данные его запустили, лог решения, результат. И все это должно быть зашифровано, подписано и защищено от взлома так, что сам бог хакеров всплакнет.

— Это как если бы твой холодильник не просто знал, что ты съел последний йогурт, — вставил Коля, — а выдавал бы нотариально заверенный протокол: «12.02.2026, 23:47, гражданин Петров совершил акт йогуртопотребления в состоянии алкогольного опьянения. Квалификация: РАЗРЕШЕНО, но осуждаемо».

— Коль, заткнись, тут серьезные вещи.

А дальше — таблицы. Сравнение с EU AI Act, с NIST, с ISO 42001. Я читаю, у меня глаз дергается. Коля делает пометки в телефоне. Жены заказывают еще вина. Много вина.

— Смотри, — говорю, — тут написано: стандарт основан на ДЕОНТОЛОГИЧЕСКОМ подходе, то есть на правилах, а не на последствиях. Это как Кант, только для роботов.

— Кант бы встал и аплодировал, — кивнул Коля. — Или потребовал бы авторские отчисления.

Дальше — про юридическую ответственность. Там есть концепция «опровержимой презумпции вины». Это значит: если ИИ накосячил, а разработчик не предоставил логи, он автоматически виноват. Не надо доказывать, что робот — дурак. Сам дурак, если логов не сохранил.

— Это гениально, — выдохнул Коля. — Это как если бы в ГАИ тебе говорили: «Вы превысили скорость. Не верите? А где ваш черный ящик? Нет черного ящика? Значит, виноваты».

Читаем дальше. Про доступ регуляторов к исходному коду. Про сравнение моделей: ЕС — защита прав граждан, Китай — защита государства, США — кусочками, как лоскутное одеяло.

— А Россия? — спросил Коля.

— Россия, — говорю, — пока в разработке. Версия бета.

Четвертый раздел — технический. Там про API, про шифрование, про защиту от утечек. Я юрист, я в этом плаваю как топор. Коля — он же технарь по первому образованию — начал делать страшные глаза и бормотать что-то про «криптографическую привязку» и «неизменяемые логи».

— Это, — сказал он, ткнув пальцем в страницу, — это архитектура доверия. Если это построить, ИИ нельзя будет наврать.

— А людей можно?

— Людей всегда можно. Но ИИ — нет.

Пятый раздел — про корпоративное управление. Там про то, что директора должны отвечать, про программы для информаторов, про опасность «этической показухи».

— «Этик-вошинг», — прочитал я по слогам. — Это когда компания делает вид, что у нее есть совесть, а на самом деле просто пиарится.

— Как наш клиент, помнишь? — хмыкнул Коля. — Который говорил, что у них «этичный AI», а на самом деле просто добавил фильтр мата в чат-боте.

— Именно.

Шестой раздел — стратегические рекомендации. Там предлагают гибридный подход: для самых опасных решений — жесткие правила, для всего остального — риск-ориентированный подход.

— Разумно, — сказал я.

— Слишком разумно, — ответил Коля. — Кто это написал? Гений?

***

И тут меня осенило. Мы же даже не посмотрели, кто автор.

Я открыл ноутбук (да, я таскаю ноутбук в ресторан, не осуждайте, у нас работа такая). Загуглил название документа.

Первая ссылка — сайт какой-то исследовательской группы. Вторая — статья в LinkedIn. Третья...

Я замер.

— Коль, — говорю тихо, — ты только послушай.

— Что?

— Автор — Лев Гукасян.

— Ну, Лев Гукасян. И что?

Я читаю дальше с экрана, и голос у меня садится:

— Льву Гукасяну сорок три года. Диагноз — рак четвертой стадии. Метастазы в печень, легкие, кости. Прогноз — от шести месяцев до года.

Тишина за столом. Даже официант, который подошел убрать тарелки, замер.

— Он написал это... — Коля прокашлялся. — Он написал 49 страниц плотнейшего анализа, сравнил три юрисдикции, предложил архитектуру, проработал юридические механизмы... когда?

— За два месяца, — говорю. — Тут написано. Начал в декабре, закончил в феврале.

— Два месяца, — повторил Коля. — Я два месяца отчет для налоговой пишу. И то не дописал.

Я листаю дальше. И нахожу еще кое-что.

— Коль... ты не поверишь. Он же еще и «Декларацию о преемственности» оформил. И «Добровольное правопреемство». Нотариально заверено, с метками времени, криптографически закреплено в блокчейне.

— В смысле?

— В смысле, он передал права на стандарт. На всю эту Тройственную моральную логику. Не коммерческой компании, не фонду, а... сообществу. Несколько организаций, университетов, независимых экспертов. Никто не владеет. Никто не контролирует. Даже если он...

— Даже если он исчезнет, — закончил Коля, — стандарт останется.

— Именно. Он убил «Bus Factor».

— Чего?

— «Bus Factor». Фактор автобуса. Знаешь, есть такой термин в управлении проектами: если ключевого разработчика собьет автобус, проект умрет. Так вот, Лев Гукасян застраховал свой проект от автобуса. От любого автобуса.

Мы сидим молча. Жены, которые уже давно не пьют вино, а просто держат бокалы, смотрят на нас с каким-то новым выражением.

— Там еще кое-что есть, — говорю я, пролистывая страницу.

— Что?

— У него есть собака. Миниатюрный шнауцер. Кличка — Винчи.

— Винчи? Как да Винчи?

— Как да Винчи. Потому что, цитирую, «маленький, бородатый и вечно что-то изобретает».

Коля расхохотался. Громко. На нас обернулись с соседних столиков.

— Это гениально, — сказал он, вытирая слезы. — Человек создает систему морали для машин, обеспечивает ее бессмертие, а свою собаку называет в честь Леонардо да Винчи. Это... это такой человеческий штрих.

Я посмотрел на экран. Там, внизу страницы, была ссылка на мессенджер. Контакт автора.

— Коль, — сказал я. — А давай?

— Чего?

— Напишем. Спросим.

— Ты с ума сошел? Человек... ну, ты понял. Ему не до нас.

— А вдруг?

Мы переглянулись. Жены переглянулись с нами. Официант переглянулся сам с собой.

Я нажал кнопку «Позвонить».

***

Экран замигал. Раз, два, три... Я уже хотел сбросить, думая «ну вот, ну и хорошо, ну и не надо», как вдруг...

— Слушаю.

Голос спокойный, чуть хрипловатый. Без трубочек, без капельниц в фоне. Обычный голос человека, который просто сидит дома и смотрит телевизор.

— З-здравствуйте, — выдавил я. — Лев? Лев Гукасян?

— Да. А вы кто?

— Мы... мы юристы. AI-юристы. Сидим в ресторане, читаем ваш документ. Сорок девять страниц. Мы... мы под впечатлением.

Пауза. Потом — смешок. Теплый такой, чуть ироничный.

— В ресторане? В субботу вечером? Читаете 49 страниц про ИИ? Ребята, у вас проблемы.

— У нас жены уже два часа пьют вино и делают ставки, когда мы сломаемся, — встрял Коля, протискиваясь к экрану.

— И когда сломаетесь?

— Мы уже сломались. На четвертом разделе, — признался я. — API, шифрование, криптографические хеши — это не наше. Мы больше по юридической части.

— А, понятно, — кивнул Лев. — Юристы. Значит, вы те, кто будет говорить, что мой стандарт невозможно имплементировать, потому что «законодательство не готово» и «нужно учитывать юрисдикционные особенности».

— Ну... да, — сказал я. — Примерно.

— И вы будете правы, — неожиданно сказал Лев. — Частично. Законодательство действительно не готово. Юрисдикционные особенности — это ад. Но знаете что?

— Что?

— Когда я начинал работать над этим, у меня было примерно полгода жизни. По прогнозам. Я не мог ждать, пока «законодательство созреет». Я просто взял и сделал то, что считал правильным.

Коля открыл рот, закрыл, снова открыл.

— Лев, — сказал он осторожно, — а зачем? Зачем вам это? С такими... обстоятельствами.

Лев посмотрел куда-то в сторону. Мы увидели край стола, чашку с чаем и... да, точно, маленькую мохнатую морду, которая ткнулась в кадр.

— Винчи, отстань, — сказал Лев беззлобно. — Дай поговорить с людьми.

Морда не отстала. Уставилась в камеру черными глазами-пуговицами.

— Знаете, — продолжил Лев, почесывая собаку за ухом, — есть такое выражение: «После меня хоть потоп». Мерзкое выражение. Эгоистичное. Я так не хочу. Я хочу, чтобы после меня осталось что-то, что не смоет первым же потопом. Что-то, что будет работать, даже когда меня не будет.

— Поэтому вы оформили преемственность? — спросил я. — Декларацию, нотариуса, блокчейн?

— Поэтому. Я не хочу, чтобы моя идея умерла вместе со мной. И не хочу, чтобы кто-то один ею владел. Тройственная моральная логика — это не продукт. Это не стартап. Это инструмент. Как... как молоток. Молотком может пользоваться кто угодно, но если ты ударишь кого-то молотком по голове — ты ответишь. Понимаете?

— Кажется, да, — сказал я. — Молоток не виноват. Виноват тот, кто им ударил.

— Именно. ИИ — это молоток. Очень сложный, умный, самообучающийся молоток. Но если он кого-то ударил — мы должны знать, кто его взял, зачем и по чьей команде. Для этого нужны логи. Для этого нужны правила. Запрещено, разрешено, обязательно. Три состояния. Всё.

— А как же... — начал Коля, но Лев перебил.

— Как же «сложность», «контекст», «нюансы»? — усмехнулся он. — Послушайте. Я умираю. Это придает мыслям определенную... ясность. Когда у тебя есть время, ты думаешь: «А давайте рассмотрим все нюансы, все контексты, создадим многоуровневую систему с исключениями и переходными периодами». Когда у тебя времени нет, ты думаешь: «Вот три корзины. Запрещено. Разрешено. Обязательно. Всё остальное — детали».

Винчи тявкнул, соглашаясь.

— А детали, — добавил Лев, — доработают другие. Если захотят. Я заложил фундамент. Пусть строят что хотят. Хотят — небоскреб, хотят — сарай. Мне уже не важно.

Мы молчали. Официант принес еще вина, но никто не притронулся.

— Лев, — сказал я наконец, — а вам не страшно? Ну... вообще?

Он посмотрел на меня. Усталые, но очень живые глаза.

— Страшно было, когда диагноз поставили. Первые две недели. А потом... знаете, есть такое понятие — «принятие». Ты принимаешь, что это случилось. И начинаешь думать: «Хорошо, у меня есть время. Что я могу сделать?» Я мог бы написать книгу. Или посадить дерево. Или родить сына. Но книги уже написаны, деревья посажены, сын вырос. А ИИ — это новая реальность. И если я могу повлиять на то, какой она будет — пусть самую малость, пусть только предложением, — я должен это сделать.

— Вы верите, что это сработает? — спросил Коля.

— Не знаю, — честно ответил Лев. — Может, да. Может, нет. Может, через десять лет все будут смеяться над этой «тройственной логикой» как над наивной попыткой загнать сложность в три ящика. А может, именно эти три ящика спасут кого-то от неправильного решения. Я не гадалка. Я инженер. Инженер строит мост. Он не знает, будут ли по нему ходить через сто лет. Но он строит так, чтобы мост не упал.

Винчи снова тявкнул, на этот раз настойчивее.

— Всё, — сказал Лев, — собака требует ужина. Извините, ребята. Рад был поговорить. Спасибо, что читаете.

— Лев! — крикнул я, когда он уже хотел отключиться. — А можно вопрос? Личный?

— Давай.

— Вот эта ваша логика... Она же про ИИ. Но люди... Люди-то как? Люди тоже иногда запрещенное делают, разрешенное путают, обязательное игнорируют. Как с этим быть?

Лев улыбнулся. Впервые за разговор — широко, открыто.

— А для людей, — сказал он, — есть совесть. Тройственная логика для машин. Людям сложнее. Им не нужны алгоритмы. Им нужно... ну, не знаю. Просто быть людьми. Винчи, например, справляется отлично. А он просто собака.

— Пока, Лев, — сказал Коля.

— Пока, ребята. Удачи с вашими исками.

Экран погас.

***

Мы сидели молча. Официант принес счет. Жены смотрели на нас с выражением «ну что, наговорились с умирающим гением?».

— Знаешь, — сказал Коля, — я думал, этот документ — про ИИ. А он, оказывается, про людей.

— Про что именно?

— Про то, что даже когда у тебя есть время только на то, чтобы дописать 49 страниц и покормить собаку, ты можешь оставить след. Не ради славы. Не ради денег. А просто потому что... ну, потому что так правильно.

— Запрещено, разрешено, обязательно, — кивнул я.

— Именно.

Мы расплатились, вышли на улицу. Ночь, звезды, где-то лает собака — не Винчи, просто какая-то местная.

— А как же твой холодильник с йогуртами? — вспомнил я.

— Что?

— Ну, который протоколы пишет. «Гражданин Петров совершил акт йогуртопотребления».

— А, — махнул рукой Коля. — Пусть пишет. Главное, чтобы не запрещал. Йогурт — это святое.

Мы рассмеялись. Где-то далеко, в другом городе, в другой квартире, Лев Гукасян кормил ужином своего миниатюрного шнауцера Винчи. А где-то в серверах, разбросанных по миру, лежала криптографическая запись о том, что Тройственная моральная логика никому не принадлежит и принадлежит всем.

Три состояния. Запрещено, разрешено, обязательно.

Как-то так.
