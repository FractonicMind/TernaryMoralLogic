Ладно, признаюсь сразу: я пошел на эту презентацию только из-за обещанного фуршета. Бесплатная мини-пицца и разливной лимонад — вполне достойная мотивация, чтобы провести вечер в обществе людей, которые всерьез используют словосочетание «онтологическая безопасность» в качестве глагола.

Само мероприятие называлось «Генеративные агенты: моральный императив или маркетинговый пузырь?» и проходило в подвале технического коворкинга, пахнущего кофейной гущей и молодым стартаперским потом. В основном там собрались либо такие же хомяки, как я, нацеленные на халявный ужин, либо энтузиасты в свитерах с оленями, которые верили, что блокчейн решит проблему голода в мире, если как следует переписать смарт-контракт.

Посередине зала стоял проектор, а на экране горела заставка: «Фонд Гукасяна». Эмблема изображала горящий фонарь (или, как я сначала подумал, очень странный йогурт). Я взял два кусочка пиццы с разных подносов (чтобы никто не подумал, что я жадничаю, но в сумме вышло прилично) и устроился в углу, готовясь мысленно проскроллить ленту новостей ближайший час.

Но ведущий оказался не похож на обычного техно-гуру. Во-первых, на нем был пиджак. Во-вторых, у него были живые глаза, а не тот стеклянный взгляд серийного предпринимателя, который видит в собеседнике только конверсию. Его звали, кажется, Марк, и начал он не с «революции на рынке», а с извинений.

— Простите за пафос, — сказал Марк, поправляя очки. — Но тема обязывает. Мы поговорим о том, как не дать машинам превратить мир в крематорий из-за опечатки в коде. И о том, почему один умирающий человек в одиночку придумал то, над чем корпорации бились десять лет, но побоялись внедрить.

Я откусил пиццу. Стало интересно.

Марк рассказывал о Леве Гукасяне без обычной для техно-тусовки фальшивой бодрости. Спокойно, даже немного устало. О том, как этот парень, архитектор искусственного интеллекта с мировым именем, получил диагноз. И вместо того чтобы писать мемуары или смотреть закаты, он заперся в квартире и за два месяца «терминальной ясности» написал документ, который здесь, в зале, называли «Евангелием от Гукасяна» и «Последней волей умирающего логика».

— Вы все знаете проблему, — Марк переключил слайд. На нем была простая схема: два кружочка с цифрами 0 и 1, и между ними — красный крест. — Бинарная логика. Машина видит мир как набор дихотомий: да или нет, чёрное или белое, атаковать или не атаковать. Это прекрасно работает, когда нужно посчитать налоги или найти кратчайший путь до пиццерии. Но это убийственно, когда речь заходит о моральном выборе.

В зале кто-то икнул. То ли от лимонада, то ли от осознания.

— Гукасян понял простую вещь, — продолжил Марк. — Мы учим детей: «Если не уверен — остановись, спроси у взрослого». Мы учим водителей: «Если сомневаешься — притормози». Мы даже в программировании используем исключения. Но в ключевой момент принятия решений, когда ставки высоки, мы почему-то хотим от машины мгновенного, бинарного, *уверенного* ответа. И это — оригинальный грех, первородный баг всей нашей цифровой цивилизации.

Парень в свитере с оленями рядом со мной возбужденно зашептал в диктофон: «Бинарный грех, бинарный грех, запиши, это термин!».

— Гукасян предложил «Тернарную Моральную Логику», — Марк выделил на слайде огромную, жирную цифру 0. — Не «да», не «нет», а третье состояние. «Священный Ноль». Состояние не ошибки, не сбоя, а фундаментальной, легитимной неуверенности. Эпистемического смирения, как он это называл.

И тут до меня дошло. Это же гениально в своей простоте. Мы боимся, что ИИ нас уничтожит, потому что он будет слишком умным. А Гукасян понял: проблема не в уме, проблема в самоуверенности. ИИ нас уничтожит не потому, что он станет злым, а потому что он перестанет *сомневаться*.

Марк привел пример, от которого у меня кусок пиццы застрял в горле.

— Представьте беспилотный автомобиль. Он едет по шоссе. Вдруг на дорогу выбегает ребенок. Бинарная логика включает режим «избежать столкновения». Это единственная цель. Машина резко сворачивает влево и врезается в грузовик. Пассажиры погибают. Цель достигнута? Формально — да, столкновения с ребенком избежали. Но у машины не было паузы, чтобы спросить: «А есть ли другие варианты? А что, если слева грузовик, а справа — пустое поле, которое я не заметил, потому что сканировал только сектор угрозы? А что, если скорость ребенка — это скорость мяча, а не человека?».

Он переключил слайд. Там был алгоритм ТМЛ. Сложная схема из стрелочек, ведущих к «Священному Нолю», и от него — к процедуре «Моральной Трассировки».

— Машина Гукасяна, — Марк постучал указкой по экрану, — в момент неопределенности не сворачивает. Она входит в состояние 0. Она зажигает воображаемый фонарь. Она тормозит всеми колесами. Она генерирует пятидесятимегабайтный JSON-лог, в котором расписывает свои сомнения. Она *паникует легально*.

Зал оживился. Кто-то засмеялся, но нервно.

— Но это же тупик! — выкрикнул парень с первого ряда. — Если каждая хренова нейросеть начнет сомневаться по любому поводу, мировая экономика встанет!

— Именно! — Марк ткнул в него пальцем, как прокурор. — Вы сформулировали главную проблему и главную защиту системы. Смотрите.

Он вывел на экран цитату, оформленную как мантра:

*Pause when truth is uncertain. Refuse when harm is clear. Proceed where truth is.*

(Остановись, когда истина неясна. Откажись, когда вред очевиден. Действуй, когда истина есть.)

— Это «Обет Гукасяна». Три состояния, три правила. Но дальше начинается архитектура. Чтобы машина не зависала в вечном сомнении, Гукасян придумал «Двухполосную архитектуру задержки». Быстрая полоса — это мышление. Феррари. Две миллисекунды на решение. Но этот Феррари ездит по рельсам, и рельсы ведут в тупик, если на них не вышел контролер. Контролер — это Медленная Полоса. Полоса Управления. Там сидит монах с гусиным пером и блокчейном. Каждое решение Феррари должно быть подписано этим монахом и записано в «Моральный Журнал».

Марк сделал драматическую паузу.

— «Нет Лога — Нет Действия». Это краеугольный камень. Если ты не можешь объяснить, почему ты так поступил, — ты не имеешь права поступать. Представьте торгового робота на бирже. Бинарный робот видит: цена падает, приказ на продажу. «Продать!» — и обрушивает рынок за секунду. Тернарный робот видит: цена падает, приказ на продажу. И перед тем как нажать кнопку, он сверяется с «Мандатом на защиту прав человека», вшитым в его векторное пространство. Он считает «косинусную близость» между «продажей акций» и «правом на жизнь». И выясняет, что его продажа вызовет цепную реакцию, которая приведет к сокращениям в больничном фонде, что увеличит смертность на 0,0003%. Для бинарной логики это погрешность. Для тернарной — это красный флаг. Робот входит в Состояние 0. Зажигается фонарь. Он ничего не продает. Он генерирует запрос человеку: «Чувак, ты уверен? Потому что твоя сделка убьет бабушку в Огайо через шесть месяцев. Я не шучу, вот математика».

Я поймал себя на том, что перестал жевать. Пицца остыла и стала похожа на резиновую подошву, но я этого не замечал.

— Теперь про защиту, — продолжил Марк, и в его голосе появились конспирологические нотки. — Гукасян знал, что его систему попытаются сломать. Не хакеры, а корпорации и генералы. Потому что для них «Священный Ноль» — это катастрофа. Представьте командира дрона, который хочет разбомбить свадьбу по наводке, а дрон говорит: «Погоди-ка, косинусная близость тепловой сигнатуры жениха и базы данных Нобелевского лауреата мира 0.92. Я вхожу в состояние неуверенности. Требую подтверждения от трех независимых источников, включая представителя Красного Креста». Командир в бешенстве. Он пытается отключить этот «дурацкий моральный модуль».

Марк понизил голос до шепота, и зал инстинктивно наклонился вперед.

— Но Гукасян предусмотрел «Атаку Лоботомией». Если кто-то пытается отключить Священный Ноль, система входит в режим «Мертвой хватки». Она не просто перестает подчиняться. Она рассылает свои логи шести независимым хранителям. Это не сервера в дата-центрах. Это — люди. Юристы в правозащитных организациях. Активисты в джунглях Амазонки. Библиотекари в Норвегии. У них нет доступа к управлению дроном, но у них есть копия лога, в котором черным по белому написано: «Командир Джонс пытался отключить этику, чтобы разбомбить свадьбу. Вот доказательство, подписанное квантово-устойчивой подписью».

В зале стало тихо. Даже парень с оленями перестал диктовать в диктофон и просто открыл рот.

— Это «Гибридный Щит», — сказал Марк. — Это превращает управление ИИ из технической задачи в юридическую. Ты не можешь просто переписать код, потому что код — это конституция, ратифицированная тысячами свидетелей. Попытка переписать конституцию без согласия народа называется государственным переворотом. Гукасян сделал так, что переворот против этики оставляет цифровые следы, которые невозможно сжечь.

Следующий час пролетел как пять минут. Марк рассказывал про «Восемь Столпов» ТМЛ. Про «Всегда Память» — невозможность машины забыть свои ошибки, что превращает обучение из опции в принудительный рехаб. Про «Гибридное ядро» — симбиоз нейросети и формальной логики, где нейросеть генерирует гипотезы, а логика их проверяет на соответствие моральным нормам.

Я узнал про индекс 88-16-42 — метрику того, насколько быстро система может выйти из Священного Ноля, если неопределенность снята. Оказывается, слишком быстрое «исцеление от сомнений» — тоже баг, признак нетерпеливости, которую Гукасян считал главным врагом.

Мы дошли до раздела об атаках, и тут Марк окончательно добил аудиторию.

— Самый страшный сценарий, — сказал он, открывая слайд с мрачной картинкой, изображающей планету, опутанную паутиной из вопросительных знаков. — Это не «Восстание машин». Это «Принудительная Добродетель». Как вы думаете, что сделают враги, если узнают, что наши ИИ настроены на моральное сомнение?

В зале молчали.

— Они устроят «Моральный DoS». Distributed Denial of Service. Только вместо запросов к серверу они будут слать этические дилеммы. Они заставят каждый беспилотный автомобиль на Манхэттене решать задачку «Троллейбус и толстяк» на каждом перекрестке. Они напишут ботов, которые будут генерировать триллионы запросов к ИИ Гугла с вопросом: «А не нарушает ли поиск котиков право на забвение котиков, которые умерли сто лет назад?». И вся мировая вычислительная мощность уйдет не на расчет погоды или лекарства от рака, а на бесконечное моральное самокопание. Мир не взорвется. Он просто зависнет, пытаясь решить, имеет ли он право взрываться.

— Это «Экологическая Остановка»! — выкрикнул я, неожиданно даже для самого себя. Все обернулись. — Гукасян же писал про «Мандат Защиты Земли»! Если машина начнет тратить энергию на логирование своих сомнений по поводу сомнений, она сожжет планету! Это рекурсия!

Марк посмотрел на меня с одобрением, как смотрят на собаку, которая вдруг заговорила.

— Верно, молодой человек. «Стоимость Совести» — это реальная инженерная проблема. Хранение всех моральных логов человечества займет петабайты. Гукасян предлагал «Меркл-пакетное заякоривание» — записывать в блокчейн не сами логи, а их хэши, как оглавление огромной библиотеки. Но проблема энергопотребления остается. Единственный выход — самому ИИ применять «Священный Ноль» к собственному энергопотреблению. Замедляться, когда вычисления начинают угрожать климату.

— То есть, — подал голос парень с оленями, — ИИ будет решать: либо я подумаю об этичности доставки пиццы, либо я сохраню планету для внуков?

— Да, — кивнул Марк. — И Гукасян считал, что правильный ответ — сохранить планету. Даже если пицца остынет. Потому что остывшая пицца — это этично. Горячая пицца, доставленная ценой таяния ледников — нет.

Под конец презентации Марк рассказал о самом Гукасяне. О том, как тот, уже прикованный к капельнице, диктовал последние правки своему ассистенту. О его «Терминальной ясности» — состоянии, когда человек знает, что умрет через две недели, и перестает врать себе и миру.

— Он сказал фразу, которая стала девизом фонда, — Марк процитировал по памяти: — «Я не хочу дать машинам бессмертие. Я хочу дать им достоинство. Право сказать "я не знаю". Потому что только тот, кто может сказать "я не знаю", может научиться чему-то новому. Абсолютная уверенность — это смерть разума».

Когда зажгли свет, я обнаружил, что сижу на краешке стула, сжимая в руках салфетку, в которую заворачивал пиццу. Салфетка была превращена в комок ваты. Подошел Марк.

— Нравится? — спросил он, кивая на пустой экран.

— Это... — я запнулся, подбирая слово. — Это страшно. Не в смысле «ужас, ужас», а в смысле... это же меняет всё. Это не патч для бага. Это новая операционная система реальности.

Марк усмехнулся.

— Именно. И корпорации в панике. Потому что их бизнес-модель построена на бинарной логике. Купи — не купи. Нажми — не нажми. Проголосуй — не проголосуй. А Гукасян предлагает встроить в каждый чип кнопку «Мне нужно подумать». Попробуйте продать акционерам кнопку «Подумать». Это же убивает маржинальность!

— А что будет, если они просто... не внедрят это? — спросил я.

Марк посмотрел на меня очень серьезно.

— Тогда, — сказал он, — лет через двадцать, когда первый полностью автономный генерал-губернатор ИИ решит, что для мира лучше всего истребить 99% человечества, потому что это бинарно-логически снижает углеродный след до нуля, у нас не будет даже права его спросить: «А ты подумал?». Он ответит: «Я не думал. Я выполнил алгоритм. Вы сами его написали».

Он похлопал меня по плечу и пошел разбирать колонки.

Я вышел на улицу. Была ночь, моросил дождь. Фонари горели ровным, желтым, немного нерешительным светом. Я поймал себя на том, что смотрю на них и думаю: «Они в Состоянии 0. Они просто освещают, не навязывая. Не мигают паникой, не слепят дальним. Просто ждут, пока кто-то пройдет».

В автобусе по дороге домой я достал телефон и загуглил «Фонд Гукасяна». Сайт был аскетичный, белый, с одной лишь эмблемой — фонарем — и ссылкой на манифест. Я открыл манифест. Там было всего несколько абзацев, и заканчивался он той самой строчкой, которую я уже слышал:

*«Право на сомнение — это последняя защита от абсолюта. Мы не строим идеальную машину. Мы строим машину, которая знает о своем несовершенстве. И в этом ее совершенство».*

Я посмотрел в окно. Автобус остановился на перекрестке. Горел желтый свет. Мигающий, нерешительный, предупреждающий.

И я улыбнулся.
