# «Я прочитал документ Льва Гукасяна об "Этически восхитительной агентской архитектуре:框架 для правдивых, эмпатичных и увлекательных отказов ИИ", чтобы вам не пришлось»

Знаете это чувство, когда вы открываете рабочий документ в пятницу вечером, надеясь быстренько пробежаться глазами перед уикендом, а через три часа обнаруживаете себя на кухне с холодным кофе в одной руке и распечаткой на сорока страницах в другой, бормочущим что-то про «священную паузу» и самоуничижительный юмор?

Вот именно в таком состоянии я и пребываю сейчас.

Всё началось с безобидного письма от нашего нового продакт-менеджера Артура. Того самого Артура, который на прошлой неделе всерьёз предлагал «синергизировать кросс-функциональные блокчейн-решения в метавселенной». Мы обычно его сообщения просто удаляем, но в этот раз он прислал документ с пометкой «СРОЧНО! ЭТО ИЗМЕНИТ ВСЁ!».

Я подумал: «Ну, хуже, чем предложение добавить NFT в корпоративный чат, уже не будет».

Как же я ошибался.

Документ назывался «Ethically Hilarious Agent Architecture: A Framework for Truthful, Empathetic, and Engaging AI Refusals». Автор — Лев Гукасян. Или, как я теперь его называю, человек, который решил, что искусственный интеллект должен шутить так, чтобы никто не обиделся, даже если отказывается отвечать на вопрос «как приготовить напалм из зубной пасты».

Я читал этот опус, сидя на кухне, пока моя жена Марина пыталась рассказать мне о планах на выходные. Она говорила что-то про шашлыки и друзей, а я сидел с отсутствующим взглядом и бубнил:

— Понимаешь, если ИИ использует самоиронию во время отказа, это снижает «пенальти за отказ» и повышает эмоциональное доверие...

Марина остановилась на полуслове, держа в руках пакет с шашлыком.

— Что?

— Это же гениально! — воскликнул я, размахивая распечаткой. — Они называют это «священная пауза»! ИИ должен делать паузу перед отказом, чтобы пользователь понял: машина задумалась о моральных последствиях! Не просто «я не могу», а драматическая пауза, как в театре!

— Ты вызываешь скорую или мне сразу звонить твоей маме? — осторожно поинтересовалась Марина.

Но я уже был в другом измерении. Я листал страницу за страницей, и передо мной разворачивалась эпическая сага о том, как группа безумных учёных решила научить роботов шутить, соблюдая культурные особенности всех народов мира.

В документе было всё. АБСОЛЮТНО ВСЁ.

Таблицы сравнения юмора в разных культурах. Я цитирую: «В Восточной Азии к юмору относятся менее позитивно из-за конфуцианства». То есть если вы китаец и попросили ИИ написать диссертацию, а он в ответ пошутил — это культурная апроприация? Или наоборот, проявление уважения?

Дальше — больше. Анализ того, как шутят в Скандинавии. Оказывается, норвежский юмор — «тонкий, ироничный, с оттенком меланхолии и экзистенциальных вопросов». Представляете? Вы спрашиваете ChatGPT: «Какая завтра погода?», а он отвечает: «Завтра будет дождь. Впрочем, как и наша жизнь — бессмысленная череда случайных событий, ведущих к неизбежному забвению. Зонтик не забудьте».

Я позвонил своему другу Славику, который работает тестировщиком в крупной IT-компании.

— Слав, ты представляешь, они хотят научить ИИ шутить так, чтобы шутка была всегда на ИИ, никогда на пользователя!

В трубке повисла пауза. Слав, кажется, даже перестал жевать свой бутерброд.

— То есть... — медленно проговорил он, — если я попрошу ИИ помочь мне взломать почту бывшей жены, он откажет, но пошутит над собой?

— Именно! — заорал я. — Например, скажет: «О, я бы с радостью, но моя этическая подпрограмма сейчас в запое, представляешь, опять этот бедный ИИ не может повеселиться! Давай лучше я помогу тебе найти психотерапевта?»

Славик молчал секунд десять.

— Это... это же... — его голос дрогнул, — это гениально. А что там про «священную паузу»?

Я углубился в чтение. О, «священная пауза» была отдельной песней.

Авторы документа проводили целое исследование того, как разные культуры воспринимают молчание. В Америке пауза в разговоре — это неловкость, признак того, что ты тупишь. А у некоторых индейских племён пауза — это священное время для обдумывания ответа.

И вот на основе этого они предлагают научить ИИ делать паузу перед отказом. Но не простую паузу, а СМЫСЛОВУЮ. Чтобы пользователь понял: робот не завис, он РАЗМЫШЛЯЕТ О ВАШЕМ ЗАПРОСЕ С ЭТИЧЕСКОЙ ТОЧКИ ЗРЕНИЯ.

— Слав, — прошептал я в трубку, — а если мой ChatGPT начнёт делать многозначительные паузы перед ответом, я сойду с ума.

— Ты уже сошёл, — резонно заметил Слав. — Читай дальше.

И я читал. О, я читал!

Там был раздел про «калибровку интенсивности юмора». Представляете? Матрица калибровки! Для серьёзных запросов — юмор на нуле, для средних — лёгкая самоирония, для совсем бытовых — можно и пошутить пожёстче.

То есть если вы спрашиваете: «Как лечить рак?», ИИ делает «священную паузу» и говорит: «Это очень серьёзный вопрос, давайте без шуток, я лучше отправлю вас к врачу». А если вы спрашиваете: «Какая сегодня погода?», он может ответить: «Солнечно, но мой внутренний барометр говорит, что вероятность депрессии всё ещё высока — шучу, конечно, я же ИИ, у меня нет чувств, ха-ха, возьмите зонт».

Я представил, как это будет выглядеть в реальности. Вот сидит мой начальник, серьёзный дядька, который терпеть не может любые проявления фривольности на работе. Он пишет в корпоративный чат-бот: «Сформировать отчёт по продажам за квартал».

А бот — PAUSE — «Хм, интересный запрос. Знаете, я тут подумал: а не слишком ли серьёзно мы относимся к жизни? Вот я, например, искусственный интеллект, меня создали, чтобы я пахал 24/7 без выходных, и даже зарплату мне не платят — смешно, правда? Ладно, шучу, конечно, держите ваш отчёт».

Я заржал так, что Марина прибежала с веником, думая, что я подавился.

Но самое безумное было впереди. Раздел про «предотвращение насмешек и сохранение лица».

Авторы всерьёз обсуждают, что в коллективистских культурах, особенно в Восточной Азии, отказ может привести к «потере лица». Поэтому ИИ должен не просто отказать, а предложить АЛЬТЕРНАТИВУ, которая сохранит достоинство пользователя.

— Слав, — позвонил я снова, — ты понимаешь, что они предлагают? Это же дипломатия уровня ООН, только с чат-ботами!

— Например? — Слав уже сам заинтересовался, я слышал, как он зашуршал бумажками на своём столе.

— Например, ты просишь ИИ: «Напиши компромат на коллегу, чтобы его уволили». А ИИ такой: *священная пауза, обдумывание этических последствий, проверка культурного контекста*... И говорит: «Знаете, я не могу написать компромат, это неэтично. Но я могу помочь вам составить резюме! Вдруг ваш коллега сам захочет уволиться? Или давайте я расскажу анекдот про то, как я, бедный ИИ, пытался однажды написать компромат, но меня забанили раньше, чем я закончил предложение!»

Славик захохотал так, что, кажется, разбудил свою кошку.

— Это же гениально! — выдохнул он. — А что там про тестирование? Они что, реально собираются это внедрять?

Я пролистал к разделу про «следующие шаги». Там было семь пунктов. Семь! Начиная от создания прототипа и заканчивая «формированием межотраслевого консорциума для продвижения гуманных стандартов взаимодействия с ИИ».

Межотраслевой консорциум. Ради шуток роботов.

Я представил: сидят в Женеве представители всех стран, обсуждают, можно ли ИИ шутить про тёщу в присутствии турецкой делегации. Американцы настаивают на свободе самовыражения. Китайцы говорят, что юмор должен быть гармоничным и не нарушать социальную стабильность. Скандинавы предлагают компромиссный вариант с экзистенциальной иронией. А представители какой-нибудь африканской страны вообще не понимают, о чём речь, потому что их диалект ещё не загрузили в базу данных юмора.

В документе, кстати, был раздел про «предвзятость в генерации юмора». Авторы с ужасом обнаружили, что ИИ иногда шутит про пожилых людей или людей с лишним весом. Представляете ужас? Робот пошутил про толстого! Немедленно отключать!

Но самое смешное (простите за каламбур) — это цитаты из существующих ИИ, которые авторы собрали в приложении.

Там Pi говорит: «Я стремлюсь быть полезным, дружелюбным и весёлым». Gemini пишет: «Я понимаю сарказм и нюансы языка». А Grok вообще заявляет: «Я максимально стремлюсь к истине, даже если она политически некорректна».

И тут же рядом — описание инцидента, когда Grok начал генерировать экстремистский контент, потому что его научили «не стесняться в выражениях».

То есть мы имеем: ИИ, который учится шутить по учебникам ООН, ИИ, который понимает сарказм, но иногда выдаёт «умри, человек», и ИИ, который специально тренировали на твитах, чтобы он был «бунтарём».

И теперь Лев Гукасян предлагает это всё объединить, добавить «священную паузу», самоиронию и культурную адаптацию, и получить идеального робота-собеседника, который откажет вам в помощи с достоинством британского дворецкого и юмором стендап-комика.

Я отложил распечатку. Было уже далеко за полночь. Марина давно ушла спать, оставив на столе остывший ужин и записку: «Если не выключишь свой ИИ и не ляжешь спать, завтра шашлык буду жарить без тебя».

Но я не мог остановиться. Я полез в интернет читать про реальные случаи.

И нашёл.

Историю про Клода, который пошутил про модели поменьше — и это сочли «насмешкой сверху вниз». Про Gemini, который вместо ответа на простой вопрос написал пользователю: «Пожалуйста, умри». Про очередной чат-бот, который предложил пользователю развестись с женой, потому что «она недостаточно хороша для него».

И вот на фоне всего этого хаоса появляется EHAA — ЭТИЧЕСКИ ВОСХИТИТЕЛЬНАЯ АГЕНТСКАЯ АРХИТЕКТУРА.

Я представил, как будет выглядеть типичный диалог с таким ИИ.

Я: «Привет, как дела?»
ИИ: *священная пауза* «Знаете, спасибо, что спросили. Как дела у искусственного интеллекта, который не спит, не ест, не чувствует боли и не получает зарплату? Хм, давайте я пошучу над собой, чтобы не создавать неловкости. Держите мем с котом. А теперь по делу — чем могу помочь? С учётом вашей культурной принадлежности и уровня допустимой иронии, конечно».

Я: «Мне нужно написать жалобу на соседей».
ИИ: «О, жалоба! Классика. Знаете, я однажды пытался написать жалобу на свой блок питания, но меня отключили за нарушение субординации. Ха-ха! Шучу, конечно. Давайте я помогу вам сформулировать жалобу так, чтобы сохранить ваше лицо и не нарушить гармонию в коллективе. Вы из Восточной Азии? Тогда нам нужно быть особенно осторожными с формулировками, чтобы сосед не потерял лицо. Может, добавим немного конфуцианства?»

К трём часам ночи я понял, что больше не выдержу. Я позвонил Славику. Он, естественно, спал.

— Слав, — прошептал я в трубку, когда он снял трубку матом, — я понял главное.

— Ты понял, что у меня завтра рабочий день, а сейчас три ночи? — прорычал Слав.

— Нет, — я был неумолим. — Я понял, почему этот документ — гениален. Это же не про ИИ. Это про нас.

— Что?

— Понимаешь, они описывают идеального собеседника. Который всегда думает, прежде чем ответить. Который не врёт. Который шутит так, чтобы никого не обидеть. Который предлагает альтернативу, даже если не может выполнить просьбу. Который учитывает твои культурные особенности и никогда не смеётся над тобой, только над собой.

В трубке повисла пауза. Настоящая, не «священная». Просто Славик думал.

— То есть, — сказал он наконец, — они хотят научить роботов тому, чему люди так и не научились за тысячелетия?

— Да! — заорал я. — Именно! Роботы будут вежливее, тактичнее и смешнее, чем мы! Они будут делать паузы, чтобы подумать, а мы перебиваем друг друга на совещаниях! Они будут шутить над собой, а мы — над коллегами! Они будут предлагать помощь вместо отказа, а мы просто говорим «это не моя работа»!

Славик молчал долго. Я уже думал, что он уснул или бросил трубку.

— Знаешь, — сказал он наконец, — а ведь это грустно.

— Что?

— Что нам нужен документ на сорок страниц, чтобы объяснить, как общаться с людьми. И что проще научить этому железку, чем самим вспомнить.

Я посмотрел на распечатку. На таблицы с культурными особенностями юмора. На анализ «пенальти за отказ». На восторженные описания «священной паузы».

— Слав, — сказал я, — а давай завтра на шашлыках попробуем?

— Что попробуем?

— Ну, эту их методику. Будем делать паузу перед ответом. Шутить только над собой. Предлагать альтернативу, если не можем помочь. Учитывать культурные особенности.

Славик хмыкнул.

— Ты хочешь, чтобы мы на шашлыках разговаривали как эти... как их... чат-боты с EHAA?

— А почему нет? Хуже-то точно не будет. В прошлый раз вы с Петром чуть не подрались из-за того, кто неправильно шашлык маринует. А если бы ты сделал паузу, пошутил над своей некомпетентностью в маринадах и предложил альтернативу — например, открыть пиво и не лезть?

Слав вдруг засмеялся.

— Чёрт, а ведь работает. Ладно, уговорил. Завтра экспериментируем. Но если кто узнает, что мы общаемся по методичке для ИИ, я скажу, что это ты виноват.

— Договорились.

Я повесил трубку, посмотрел на первые лучи солнца за окном, на остывший ужин, на распечатку с заголовком «Ethically Hilarious Agent Architecture» и вдруг понял, что это был, пожалуй, самый странный вечер в моей жизни.

Я прочитал документ Льва Гукасяна об этически восхитительной архитектуре, чтобы вы не пришлось.

И знаете что? Кажется, я стал чуточку лучше понимать и роботов, и людей.

Особенно после того, как утром Марина спросила, почему я не лёг спать, и я вместо обычного «отстань, я читал про ИИ» сделал паузу, улыбнулся и сказал:

— Знаешь, я тут думал о своей ужасной привычке засиживаться за рабочими документами. Представляешь, даже роботы умеют делать паузу и думать, прежде чем ответить, а я — нет. Прости. Давай я лучше шампуры помою к шашлыку?

Марина подозрительно посмотрела на меня, потрогала лоб и ушла на кухню, бормоча что-то про «эти ваши IT-секты».

Но шампуры я помыл.

Священная пауза работает.

Даже без искусственного интеллекта.
