# Хроники Терминала: Три Состояния Будущего

---

Она появилась в нашем чате в 3:47 ночи.

«Вы не поверите, что я нашла в архиве диссертаций», — написала Алиса и прикрепила PDF.

Я лежал на кровати в общежитии МФТИ, пытался понять квантовую механику и одновременно не понимал, зачем вообще пытаюсь. За окном декабрь красил Москву в цвета мокрого асфальта и неоновых вывесок. Дима рядом щёлкал таском по наушнику в «Доте». Катя, наша вечная мать Тереза с кофе и эсэмэсками от родителей, которые она никогда не читала вовремя, подняла голову от ноутбука.

«Сорок страниц? — лениво отозвался Дима, не отрываясь от экрана. — Я лучше десять калибров фарма залью, чем сорок страниц читать. Там хоть картинки есть?»

«Там есть кое-что получше, — голос Алисы в аудиосообщении звучал так, будто она нашла Святой Грааль в мусорном баке. — Там есть парень, который решил переписать правила игры, потому что умирает».

Дима снял наушник. Катя отложила телефон. Я закрыл учебник Ландау—Лифшица и почувствовал, как эта ночь перестаёт быть обычной.

---

Название документа было высечено на титульном листе шрифтом, который явно не планировал никому нравиться:

**«Подпись Создателя: Происхождение, Неизменность и Целостность в Фундаментальных Структурах Ответственности»**

Автор: Лев Гукасян.

«Лев, — прочитала Катя вслух. — Лев. Как Толстой. Только этот, похоже, решил написать не "Войну и мир", а "Как не дать машинам уничтожить человечество". По мелочи».

Алиса сбросила голосовое с цитатой из первого абзаца. Я слушал и чувствовал, как внутри закипает то самое раздражение, которое возникает, когда кто-то говорит правду настолько очевидную, что её невозможно оспорить, но все почему-то делают вид, что это просто интересная теория.

*«Интеграция искусственного интеллекта в критическую инфраструктуру — от финансовых расчётных палат до автономных систем обороны — создала кризис ответственности. Современные архитектуры ИИ оптимизируют вычислительную эффективность и минимизируют задержки, рассматривая этическое логирование и аудиторские цепочки как пост-обработку, а не как фундаментальные ограничения»*.

Дима, который до этого момента искренне полагал, что «этика ИИ» — это когда нейросеть отказывается генерировать порнографию с участием публичных лиц, вдруг замер.

«Подожди, — сказал он. — Перечитай последнее предложение».

Алиса перечитала.

«То есть, — Дима говорил медленно, как человек, который только что понял, что все эти годы пил воду из крана, а соседи травились свинцом, — они специально проектируют системы так, чтобы ответственность можно было размазать? Это не баг? Это фича?»

«Это архитектура, — ответила Алиса. — И автор документа говорит, что единственный способ это исправить — встроить ответственность на уровень ядра. Не как надстройку. Как конституцию».

Катя вздохнула. Она всегда вздыхала, когда кто-то произносил слово «конституция» в контексте, не связанном с днём рождения её дедушки-юриста.

«Звучит как утопия, — сказала она. — Красиво, но в реальности…»

«В реальности, — перебила Алиса, — автор этого документа узнал, что у него рак. Терминальная стадия. И вместо того, чтобы составлять список мест, куда он хотел бы поехать, он составил список того, как перепроектировать всю мировую финансовую систему».

Тишина в комнате стала осязаемой. Даже Дима перестал делать вид, что его вообще интересует «Дота».

«То есть, — я наконец подал голос, — мужик смотрит смерти в лицо и думает: "Знаете, чего не хватает высокочастотному трейдингу? Кнопки 'Стоп'"?»

«Не просто кнопки, — голос Алисы дрогнул. — Кнопки, которую нельзя обойти. Которая вшита в архитектуру. Которая не даст системе совершить действие, пока она не подтвердит, что понимает последствия».

Дима хмыкнул.

«Я знаю только одну кнопку, которую нельзя обойти, — сказал он. — И она обычно ведёт в морг».

---

Дальше было вот что.

Документ, который мы читали (вернее, который Алиса читала вслух, а мы слушали, залипая в экраны, будто это новый сезон «Чёрного зеркала»), оказался не просто академической статьёй. Это была техническая спецификация. Чертеж машины, которая не может врать.

Алиса называла это «Восемью Столпами Тернарной Моральной Логики». Я называл это «Восемью Способами Разрушить Карьеру Любого Продукт-менеджера, Который Привык Срезать Углы».

Дима называл это «Аниме про меха-демонов, только вместо демонов — блокчейн».

**Столп Первый: Священный Ноль.**

«Состояние, в которое входит система, — читала Алиса, — когда она сталкивается с этической неопределённостью. Продолжение работы невозможно без внешнего подтверждения. Ноль — не отсутствие значения. Ноль — это выбор не выбирать».

«То есть, — перевела Катя на человеческий, — машина говорит: "Я не знаю. Помогите". И стоит на месте, пока помощь не придёт».

«И её нельзя заставить заткнуться и гадать дальше», — добавил Дима.

«И её нельзя заставить заткнуться и гадать дальше», — подтвердила Алиса.

Мы помолчали. Где-то за стеной сосед учил гитару, и до нас долетали обрывки «Кино». Цой пел о том, что ждёт ответа. Наверное, это был знак.

**Столп Второй: Всегда Память.**

«Намерение совершить действие должно быть зафиксировано до того, как действие выполнено. Журнал — не отчёт о прошлом. Журнал — это разрешение на будущее».

«Так не работает, — сказал Дима. — Нигде так не работает. Сначала трейд, потом подтверждение. Сначала выстрел, потом отчёт. Если ждать подтверждения — рынок уйдёт. Враг выстрелит первым».

«Рынок уйдёт, — согласилась Алиса. — А враг, может быть, выстрелит. Но ты хотя бы будешь знать, кто именно отдал приказ стрелять».

Дима хотел возразить, но почему-то не смог.

**Столп Третий: Обещание Гукасяна.**

Вот здесь стало по-настоящему странно.

«Обещание состоит из трёх частей, — объявила Алиса тоном человека, который читает заклинание. — Фонарь. Подпись. Лицензия».

Фонарь — это видимый всем сигнал. «ЭТИЧЕСКАЯ ПАУЗА». Никаких тихих ошибок. Никакого «fail silent». Если система не знает, что делать, она не просто падает молча. Она кричит.

Подпись — это идентификатор ORCID. **0009-0006-5966-1243**.

«Это номер Гукасяна, — сказала Алиса. — Он вшит в код. Вы не можете его удалить. Это криптографический корень доверия».

«То есть, — я попытался осмыслить услышанное, — этот мужик привязал свою личность к системе так жёстко, что если вы попытаетесь оторвать этикетку "Сделано Львом Гукасяном", система просто перестанет работать?»

«Да».

«И он сделал это добровольно?»

«Да».

«Зачем?»

Алиса пролистнула несколько страниц и нашла абзац, обведённый, судя по всему, самим автором в квадрат.

*«Атрибуция — не уязвимость. Атрибуция — это функция. Системы, созданные для избегания ответственности, неизбежно продуцируют вред. Единственный способ гарантировать, что создатель не сможет отречься от последствий — сделать отречение технически невозможным».*

«Он поставил своё имя на бомбу, — сказал Дима. — И сделал так, что её нельзя взорвать анонимно».

«Или, — поправила Катя, — он поставил своё имя на спасательный круг. Чтобы каждый, кто за него ухватится, знал, кто его бросил в воду».

---

Дальше были Столпы с четвёртого по восьмой, и каждый звучал как приговор текущему положению вещей.

**Столп Четвёртый: Мандат Защиты Земли.**

Международные экологические соглашения — Парижское, Киотское, всё, что человечество смогло подписать, пока не переругалось окончательно — встроены в систему как векторы ограничений. Если действие похоже на вред природе, система тормозит.

«Представьте, — сказала Алиса, — что нефтяная платформа не может начать бурение, пока не докажет, что это не уничтожит миграционные пути китов».

«Представьте, — добавил я, — что китам вообще плевать на наши доказательства».

«Но система хотя бы заставит нас сделать паузу и подумать», — сказала Катя.

И никто не спорил.

**Столп Пятый: Двойная Полоса Задержки.**

Быстрый трек — для действий. Медленный трек — для аудита. Система не может двигаться быстрее, чем способна фиксировать собственные решения. Если аудит-полоса переполняется, действие автоматически замедляется.

«Это как скоростной лимит, — объяснил Дима, который на удивление быстро въезжал в концепцию. — Только вместо штрафа — просто невозможно превысить».

«Капитализм не любит лимиты», — заметил я.

«Капитализм любит, когда никто не смотрит, — поправила Алиса. — А эта система смотрит всегда».

**Столп Шестой: Меркл-пакетное Хранение.**

Корни хешей уходят в блокчейн. Не в частный реестр, который можно подчистить задним числом. В публичные, не поддающиеся цензуре сети. Историю нельзя переписать.

«Значит, — сказала Катя, — если ты принял плохое решение, оно останется с тобой навсегда».

«Если ты принял хорошее решение, — уточнил Дима, — оно тоже останется с тобой навсегда».

«Гукасян, видимо, верил, что хороших решений больше», — сказала Алиса.

Мы не знали, верил ли он в это на самом деле. Но документ был написан так, будто да.

**Столп Седьмой: Гибридный Щит.**

Критические решения требуют подтверждения от независимой системы или сети «узлов-свидетелей». Один алгоритм не может решить судьбу мира. Нужен консенсус.

«Демократия, — сказал Дима. — Он встроил в машину демократию».

«Демократию с правом вето», — уточнила Алиса.

«Демократию, которая работает», — вздохнула Катя.

**Столп Восьмой: Публичные Блокчейны.**

Последний уровень. Якорь. Точка невозврата. Моральные логи не лежат в чьём-то закрытом дата-центре. Они размазаны по сети так широко, что их невозможно выкурить.

«Зачем?» — спросил Дима.

«Чтобы никто не мог прийти и сказать: "Этих логов никогда не существовало", — ответила Алиса. — Потому что они есть у всех».

---

Мы дошли до раздела «Фактор Автобуса».

Так в разработке называют вопрос: «Что случится с проектом, если ключевого разработчика собьёт автобус?».

В случае Гукасяна вопрос звучал иначе: «Что случится с системой, если Гукасян умрёт от рака?»

Он предусмотрел это.

Юридические и технические механизмы передачи «ключа подписи» фонду или трасту. Система, которая может пережить своего создателя. Наследие, которое не умирает вместе с телом.

«Он проектировал бессмертие, — тихо сказала Катя. — Не для себя. Для идеи».

«Или, — сказал я, — он просто не хотел, чтобы всё, что он построил, развалилось, когда его не станет. Это не бессмертие. Это ответственность».

Алиса закрыла документ.

«Заключение, — сказала она. — Я прочитаю последний абзац».

Она прочитала.

*«Тернарная Моральная Логика не является технологическим решением. Она является конституционной поправкой к эпохе искусственного интеллекта. Священный Ноль — это не баг и не фича. Это право машины на сомнение. И право человека — требовать ответа».*

Мы сидели в тишине, пока Цой за стеной не допел свою песню.

Дима нарушил молчание первым.

«Этот Гукасян, — сказал он. — Лев. Он вообще понимает, что сделал?»

«Думаю, — ответила Алиса, — именно поэтому он это и сделал. Потому что понимал».

---

Я не спал до утра.

Гуглил. Читал форумы. Нашёл тот самый репозиторий на GitHub — FractonicMind/TernaryMoralLogic, с коммитами, уходящими в ноябрь. Нашёл пост на Хабре, где кто-то пытался объяснить концепцию «Всегда Памяти» через аллюзии к «Помни меня» Нолана. Нашёл тред на Reddit, где люди спорили, является ли ORCID Гукасяна актом гениальности или актом безумия.

(Ответ: и тем, и другим. Потому что только гениальный безумец мог вшить собственное имя в код так глубоко, что его невозможно оттуда выдрать, и назвать это не багом, а архитектурой.)

А потом я нашёл интервью. Гукасян дал его за месяц до публикации документа. Журналист спросил: «Вы не боитесь, что вашу систему используют во вред?»

Гукасян ответил: «Я боюсь не этого. Я боюсь, что её не используют вообще. Потому что тогда победит архитектура, в которой можно сделать что угодно и никогда за это не ответить».

Пауза.

«Знаете, — добавил он, — умирать страшно. Но ещё страшнее умирать в мире, где у машин нет кнопки "Стоп", а у людей нет имён».

---

На следующее утро мы встретились в столовой. Дима пил кофе и смотрел в телефон с выражением лица человека, который только что осознал, что вселенная устроена сложнее, чем он думал.

Катя молчала и рисовала на салфетке восьмиугольник. Восемь сторон. Восемь столпов.

Алиса пришла последней, села и сказала:

«Я не знаю, что с этим делать. Но я знаю, что не могу теперь об этом не думать».

«Добро пожаловать в клуб», — сказал я.

Мы сидели и смотрели, как за окном декабрьское утро пытается пробиться сквозь тучи. Московское небо было цвета старого асфальта, и это почему-то казалось правильным.

«Знаете, что самое безумное? — спросил Дима. — Этот парень не просто написал манифест. Он написал код. Работающий код. Который можно взять и использовать. Прямо сейчас».

«Использовать для чего?» — спросила Катя.

Дима пожал плечами.

«Для всего. Для банковских транзакций. Для систем голосования. Для дронов. Для чат-ботов, которые не хотят становиться расистами. Всё, что принимает решения, можно прогнать через эту архитектуру».

«Всё, что принимает решения, — повторила Алиса. — И все, кто их принимает».

Мы переглянулись.

Я вдруг понял, что сорок страниц технического текста каким-то образом изменили то, как мы смотрим на мир. Раньше проблемы казались сложными, запутанными, неразрешимыми. Теперь у них появилась форма. Восьмиугольник. Три состояния.

Священный Ноль.

«А что, если, — начал я медленно, — это не про машины?»

Они посмотрели на меня.

«Что, если Гукасян на самом деле написал инструкцию для людей? Просто замаскировал её под код, чтобы мы наконец прочитали?»

Катя отложила салфетку.

«Три состояния, — сказала она. — Действуй, когда уверен. Пауза, когда сомневаешься. Отказ, когда это причиняет вред».

«Всегда помни, — добавила Алиса. — Не стирай историю. Не переписывай прошлое».

«И ставь своё имя, — закончил Дима. — Под каждым решением. Чтобы никто не мог спрятаться».

Мы замолчали.

Где-то за окном Москва просыпалась, заводила моторы, открывала кофейни, запускала серверы, совершала сделки, принимала решения. Мир продолжал вращаться по старым законам, где ответственность — это то, что можно размыть, переложить, забыть.

Но теперь у нас была карта другого мира.

Мира, где будущее имеет три состояния.

Мира, построенного человеком, который посмотрел смерти в глаза и сказал: «Я ещё не закончил».

---

*Примечание автора: этот рассказ — художественная интерпретация реальных концепций, найденных в документе о Тернарной Моральной Логике. Любое сходство с реально существующим умирающим исследователем, который решил перепроектировать этику ИИ вместо того, чтобы писать завещание — скорее всего, не случайность. Потому что Лев Гукасян действительно существует. И его документ действительно лежит в открытом доступе.*

*И если вы сейчас читаете эти строки и чувствуете тот же холодок узнавания, который почувствовали мы той декабрьской ночью — значит, Священный Ноль сработал.*

*Система вошла в состояние паузы.*

*Дальше — ваше решение.*
