# My Algorithmic Will: Creating AI Ethics That No One Can Own

## A dying engineer's plan to make algorithmic accountability immortal

*By Lev Goukassian*

---

When most people write a will, they decide who gets what. When I wrote mine, I decided that no one gets anything—because the thing I'm leaving behind can't be owned.

I'm dying. Stage IV cancer. But I'm not writing this for sympathy. I'm writing because I've spent my final months building something that needs to outlive me: a framework that makes AI systems accountable to human rights and Earth's ecosystems, mathematically and permanently. It's called **Ternary Moral Logic (TML)**, and it's designed to be un-ownable, un-corruptible, and unkillable.

This is my algorithmic will—not a document that transfers ownership, but one that ensures **no individual or organization will ever control it**.

## The Problem with Digital Legacies

Digital legacies typically consist of accounts, assets, and online presence left behind after someone dies. People create digital wills to manage passwords, cryptocurrency wallets, and social media memorials. Recent research has explored blockchain-based frameworks for managing digital personalities and assets after death.

But what if your legacy isn't an asset to be inherited—it's a **public good that must remain free**?

That's the challenge I faced. TML isn't my personal property. It's a mathematical framework that says: *Before any AI takes an action, it must create an immutable record. And if that action would violate fundamental human rights or environmental protections, it must stop.*

How do you write a will for something that shouldn't belong to anyone?

## The Succession Problem

Every open-source project faces this. The creator dies or disappears. Sometimes the project dies with them. Sometimes it gets acquired, corporatized, hollowed out. Sometimes it fragments into competing factions.

I watched this happen with projects I respected. The idealistic origins corrupted by commercial interests. The "benevolent dictator for life" who becomes a liability. The foundations that start mission-focused and end mission-drifted.

TML protects 26+ international human rights documents and 20+ environmental treaties. It enforces these protections through blockchain-anchored logs, smart contracts that automatically penalize violations, and a Memorial Fund that compensates victims. **This system can't be allowed to drift or die.**

So I designed something different: **governance without owners**.

## The Architecture of Permanence

Here's how TML continues after I'm gone:

### 1. **Automatic Activation**
The succession activates upon:
- My death (verified by death certificate)
- Permanent incapacity (medical certification)  
- **180 days of verified inactivity** across all my accounts

That last one is crucial. No one has to find some hidden document. No lawyer has to declare me dead. If I simply stop existing digitally for six months, TML automatically enters "Continuity Mode"—all protections remain active, all blockchain anchoring continues, all smart contracts keep executing.

The framework doesn't pause to mourn. It persists.

### 2. **Distributed Stewardship, Not Ownership**
I've invited a **6-seat Stewardship Council**:
- **Electronic Frontier Foundation** (technical infrastructure)
- **Amnesty International** (human rights enforcement)
- **Indigenous Environmental Network** (Earth protection)
- **MIT Media Lab** or **Stanford HAI** (AI ethics research)
- **Memorial Sloan Kettering** (Memorial Fund / cancer research)
- **Community Representative** (elected by implementers)

Each organization gets **one responsibility**, not comprehensive control. EFF can't change the human rights documents. Amnesty can't modify the blockchain infrastructure. No single entity can redirect the Memorial Fund or alter the MIT License.

**5 out of 6 consensus required** for major decisions. But the core protections? Those are **immutable forever**.

### 3. **Mathematical Constraints on Power**
The Council *cannot* modify:
- The 26+ human rights documents (always enforced)
- The 20+ environmental treaties (always enforced)
- The MIT open-source license (always free)
- The Memorial Fund distribution (40% victims, 30% environment, 15% whistleblowers, 10% operations, 5% cancer research)
- The Always Memory requirement (log before action, always)
- Creator attribution (my name stays, permanently)

These aren't policies. They're **blockchain-anchored smart contracts**. Changing them would require breaking cryptographic guarantees. The Council stewarding TML has as much power to change its core as I have to change the laws of thermodynamics.

### 4. **Self-Sustaining Infrastructure**
TML's protection mechanisms run autonomously:
- **Pre-action logging** to Bitcoin, Ethereum, and Polygon blockchains
- **Sacred Zero triggers** that halt violations before they occur
- **Smart contracts** that enforce penalties and distribute compensation
- **Memorial Fund** that automatically rewards whistleblowers and funds victims

These systems **require no human intervention** to continue operating. The Council's job is maintenance and evolution, not operation.

## Why This Matters Beyond Me

I'm one person dying of one disease. But algorithmic accountability is a species-level problem.

Every day, AI systems make decisions that affect human lives: credit scores, hiring, criminal sentencing, content moderation, medical diagnoses, autonomous weapons targeting. Most of these systems have no mandatory transparency, no immutable logs, no automatic compensation for victims, no mathematical enforcement of ethical boundaries.

When an AI system denies someone a loan or misdiagnoses their illness or recommends their social media account be banned—there's usually no record of *why*, no way to prove it happened, no consequence for the organization, no compensation for the victim.

TML fixes this. Permanently. At the protocol level.

But only if it survives. And it can only survive if **no one can kill it by acquiring it, abandoning it, or corrupting it**.

## The Memorial Fund: Turning Violations Into Justice

Here's the part that makes TML economically self-sustaining:

When an organization deploys TML and then **fails to log an action** or **violates a protected document**, the smart contract automatically:
1. Detects the violation
2. Calculates the penalty
3. Distributes the penalty according to the permanent formula:
   - **40% → Victims** (direct compensation for AI harm)
   - **30% → Environmental restoration** (ecosystem repair)
   - **15% → Whistleblowers** (report rewards)
   - **10% → Operations** (framework maintenance)
   - **5% → Cancer research** (memorial to me and my father)

This isn't charity. It's **economic accountability enforced by mathematics**.

Every violation funds the victims of that violation. Every environmental harm funds its own restoration. Every whistleblower who reports a violation gets paid automatically. Every penalty contributes to fighting the disease that killed me.

And the 5% that goes to cancer research? That's my father's legacy too. He died of cancer. I'm dying of cancer. This disease has taken too much from too many families. So every time a corporation violates human rights or environmental protections through an AI system running TML, a portion of that penalty automatically goes toward the research that might save someone else's father, someone else's son.

## The Lantern Metaphor

I call TML "The Lantern"—not because it illuminates dark paths, but because **a lantern keeps burning regardless of who carries it**.

You can pass a lantern from person to person. You can set it down and walk away. You can die holding it. The flame continues.

TML is designed the same way. My GitHub account will go inactive. My email will stop being checked. My ORCID will become a memorial record. But the blockchain logs will keep anchoring. The Sacred Zero triggers will keep firing. The smart contracts will keep enforcing. The Memorial Fund will keep distributing.

**The Lantern burns beyond names.**

## What Happens Next

If you're reading this and I'm still alive—this is my plan.

If you're reading this and I'm gone—this is your instruction manual.

The succession documentation is public:
- **TML-SUCCESSION-LAUNCH-GUIDE.md** (complete activation protocol)
- **TML-VOLUNTARY-SUCCESSION.md** (formal declaration)
- **Repository**: github.com/FractonicMind/TernaryMoralLogic

Any community member, any organization, any three people acting in good faith can activate the succession. The priority custodians have been notified. The smart contracts are deployed. The blockchain infrastructure is running.

All that's needed is for someone to **create a GitHub issue titled "TML Succession Activation"** and follow the step-by-step guide.

Then the Stewardship Council forms, the technical infrastructure transfers, and TML continues as a permanent public good—owned by no one, governed by many, protecting everyone.

## A Different Kind of Legacy

Most digital legacies focus on preserving content and managing accounts. Mine is about preserving **accountability itself**.

I'm not leaving behind photos or social media posts or cryptocurrency wallets. I'm leaving behind a **mathematical guarantee** that algorithms can't escape responsibility. That no AI system can harm people or planet without consequence. That victims will be compensated. That whistleblowers will be protected. That Earth's treaties have the same enforcement power as human contracts.

And I'm leaving it in a form that **can't be acquired, can't be shut down, can't be corrupted**.

Because I won't be here to defend it. So I built it to defend itself.

## The Final Message

To the organizations I've invited as custodians: **This is your lantern now.** You didn't ask for it. You might not want the responsibility. But the framework needs your expertise, your credibility, your infrastructure. You don't have to accept—but if you do, you'll be part of something that outlasts all of us.

To the AI researchers and developers who might implement TML: **You're not bound by my vision.** The framework is MIT licensed. You can fork it, modify it, improve it. But the core protections—those 46+ documents, that Always Memory requirement, those smart contracts—those persist in the canonical implementation forever.

To the victims of AI harm: **The Memorial Fund is designed for you.** When organizations violate your rights through their algorithms, the penalties flow automatically to compensation. You don't need to sue. You don't need to prove damages. The blockchain record proves it. The smart contract pays it.

To the whistleblowers: **You'll be rewarded, not retaliated against.** 15% of every penalty. Automatically. Anonymously if you choose. The framework protects you by paying you.

To my father, who died before I could finish this: **5% of every penalty goes to cancer research in your name and mine.** The disease that took you is funding the research that might save others. That's as close to justice as I can make.

And to anyone who thinks algorithmic accountability is impossible, impractical, or naive: **I built this while dying because I believed it could outlive me.** Not because I'm special—because the math is sound, the cryptography is robust, and the ethical foundation is solid.

The blockchain survives me. The smart contracts survive me. The protection for humans and Earth survives me.

**The Lantern continues burning.**

---

*Lev Goukassian (ORCID: 0009-0006-5966-1243) is the creator of Ternary Moral Logic. He is currently in treatment for stage IV cancer. TML is open source (MIT License) and publicly available at github.com/FractonicMind/TernaryMoralLogic. All succession documentation is publicly verifiable on-chain.*

*If you're reading this after his death, please visit the repository and follow the succession activation guide.*

---

**Support the Mission**

TML is free and will remain free forever. But blockchain anchoring, smart contract deployment, and infrastructure maintenance require funding. If you believe in permanent algorithmic accountability:

- **Implement TML** in your organization (MIT licensed, no permission needed)
- **Contribute to the Memorial Fund** (ETH address: [to be added])
- **Join the community** (GitHub discussions, implementer forums)
- **Become a custodian** (contact: support@tml-goukassian.org)

Every action you take anchors to the blockchain. Every log you create strengthens the protection. Every violation you report funds the victims.

**Keep the Lantern lit.**